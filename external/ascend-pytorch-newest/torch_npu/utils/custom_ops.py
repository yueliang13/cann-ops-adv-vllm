import warnings
import torch
import torch_npu


torch_npu.npu_ciou_backward = torch.ops.npu.npu_ciou_backward
torch_npu.npu_hans_decode = torch.ops.npu.npu_hans_decode
torch_npu.npu_nsa_select_attention = torch.ops.npu.npu_nsa_select_attention
torch_npu.npu_convolution = torch.ops.npu.npu_convolution
torch_npu.repeat_interleave_backward_tensor = torch.ops.npu.repeat_interleave_backward_tensor
torch_npu.npu_fused_attention_score_backward = torch.ops.npu.npu_fused_attention_score_backward
torch_npu.npu_stride_copy = torch.ops.npu.npu_stride_copy
torch_npu.npu_dropout_gen_mask = torch.ops.npu.npu_dropout_gen_mask
torch_npu.npu_lstm_cell_backward = torch.ops.npu.npu_lstm_cell_backward
torch_npu.npu_broadcast = torch.ops.npu.npu_broadcast
torch_npu.npu_conv3d_backward = torch.ops.npu.npu_conv3d_backward
torch_npu.npu_moe_init_routing_v2 = torch.ops.npu.npu_moe_init_routing_v2
torch_npu.npu_swiglu = torch.ops.npu.npu_swiglu
torch_npu.npu_lstm_data = torch.ops.npu.npu_lstm_data
torch_npu.npu_dropout_with_add_softmax = torch.ops.npu.npu_dropout_with_add_softmax
torch_npu.npu_dequant_bias = torch.ops.npu.npu_dequant_bias
torch_npu.npu_hans_encode = torch.ops.npu.npu_hans_encode
torch_npu.npu_fused_attention_score_grad = torch.ops.npu.npu_fused_attention_score_grad
torch_npu.npu_moe_distribute_dispatch_v2 = torch.ops.npu.npu_moe_distribute_dispatch_v2
torch_npu.npu_quantize = torch.ops.npu.npu_quantize
torch_npu.npu_geglu = torch.ops.npu.npu_geglu
torch_npu.npu_rotated_overlaps = torch.ops.npu.npu_rotated_overlaps
torch_npu.npu_rotary_mul = torch.ops.npu.npu_rotary_mul
torch_npu.npu_moe_token_unpermute = torch.ops.npu.npu_moe_token_unpermute
torch_npu.npu_nsa_select_attention_infer = torch.ops.npu.npu_nsa_select_attention_infer
torch_npu.npu_random_choice_with_mask = torch.ops.npu.npu_random_choice_with_mask
torch_npu.npu_moe_token_permute = torch.ops.npu.npu_moe_token_permute
torch_npu.npu_bmm_v2_mat2_backward = torch.ops.npu.npu_bmm_v2_mat2_backward
torch_npu.npu_bmmV2 = torch.ops.npu.npu_bmmV2
torch_npu.npu_gemma_rms_norm = torch.ops.npu.npu_gemma_rms_norm
torch_npu.stft_backward = torch.ops.npu.stft_backward
torch_npu.npu_swiglu_backward = torch.ops.npu.npu_swiglu_backward
torch_npu.npu_confusion_transpose_backward = torch.ops.npu.npu_confusion_transpose_backward
torch_npu.npu_moe_gating_top_k_softmax = torch.ops.npu.npu_moe_gating_top_k_softmax
torch_npu.npu_binary_cross_entropy_with_logits_backward = torch.ops.npu.npu_binary_cross_entropy_with_logits_backward
torch_npu.npu_conv_transpose2d = torch.ops.npu.npu_conv_transpose2d
torch_npu.npu_fused_attention_score = torch.ops.npu.npu_fused_attention_score
torch_npu.npu_roi_alignbk = torch.ops.npu.npu_roi_alignbk
torch_npu.npu_apply_adam_w = torch.ops.npu.npu_apply_adam_w
torch_npu.npu_view_copy = torch.ops.npu.npu_view_copy
torch_npu.get_storage_size = torch.ops.npu.get_storage_size
torch_npu.npu_stride_add = torch.ops.npu.npu_stride_add
torch_npu.npu_convolution_transpose = torch.ops.npu.npu_convolution_transpose
torch_npu.npu_quant_matmul_dequant = torch.ops.npu.npu_quant_matmul_dequant
torch_npu.fast_gelu = torch.ops.npu.fast_gelu
torch_npu.npu_max = torch.ops.npu.npu_max
torch_npu.npu_anchor_response_flags = torch.ops.npu.npu_anchor_response_flags
torch_npu.npu_convolution_transpose_backward = torch.ops.npu.npu_convolution_transpose_backward
torch_npu.npu_iou = torch.ops.npu.npu_iou
torch_npu.npu_grouped_matmul_add_ = torch.ops.npu.npu_grouped_matmul_add_
torch_npu.npu_fused_attention_score_fwd = torch.ops.npu.npu_fused_attention_score_fwd
torch_npu.npu_add_rms_norm_quant = torch.ops.npu.npu_add_rms_norm_quant
torch_npu.npu_conv2d_backward = torch.ops.npu.npu_conv2d_backward
torch_npu.repeat_interleave_backward_int = torch.ops.npu.repeat_interleave_backward_int
torch_npu.npu_mla_prolog = torch.ops.npu.npu_mla_prolog
torch_npu.npu_dynamic_quant_asymmetric = torch.ops.npu.npu_dynamic_quant_asymmetric
torch_npu.empty_with_format = torch.ops.npu.empty_with_format
torch_npu.npu_nsa_compress_attention_infer = torch.ops.npu.npu_nsa_compress_attention_infer
torch_npu.npu_dropout_do_mask = torch.ops.npu.npu_dropout_do_mask
torch_npu._dropout_with_byte_mask = torch.ops.npu._dropout_with_byte_mask
torch_npu.npu_mrope = torch.ops.npu.npu_mrope
torch_npu.npu_reshape = torch.ops.npu.npu_reshape
torch_npu.npu_ciou = torch.ops.npu.npu_ciou
torch_npu._dropout_with_byte_mask_backward = torch.ops.npu._dropout_with_byte_mask_backward
torch_npu.npu_masked_softmax_with_rel_pos_bias = torch.ops.npu.npu_masked_softmax_with_rel_pos_bias
torch_npu.npu_trans_quant_param = torch.ops.npu.npu_trans_quant_param
torch_npu.npu_weight_quant_batchmatmul = torch.ops.npu.npu_weight_quant_batchmatmul
torch_npu.npu_rotated_iou = torch.ops.npu.npu_rotated_iou
torch_npu.npu_ps_roi_pooling_backward = torch.ops.npu.npu_ps_roi_pooling_backward
torch_npu.npu_fast_gelu_backward = torch.ops.npu.npu_fast_gelu_backward
torch_npu.npu_dtype_cast = torch.ops.npu.npu_dtype_cast
torch_npu.npu_gelu_backward = torch.ops.npu.npu_gelu_backward
torch_npu._conv_depthwise2d_backward = torch.ops.npu._conv_depthwise2d_backward
torch_npu.npu_nsa_compress_infer = torch.ops.npu.npu_nsa_compress_infer
torch_npu.npu_nms_with_mask = torch.ops.npu.npu_nms_with_mask
torch_npu.npu_fused_attention_layernorm_qkv_fwd = torch.ops.npu.npu_fused_attention_layernorm_qkv_fwd
torch_npu._npu_silent_check_v3 = torch.ops.npu._npu_silent_check_v3
torch_npu.npu_nms_rotated = torch.ops.npu.npu_nms_rotated
torch_npu.npu_group_quant = torch.ops.npu.npu_group_quant
torch_npu.batch_norm_reduce = torch.ops.npu.batch_norm_reduce
torch_npu.npu_bounding_box_encode = torch.ops.npu.npu_bounding_box_encode
torch_npu.npu_cross_entropy_loss_backward = torch.ops.npu.npu_cross_entropy_loss_backward
torch_npu._npu_silent_check_v2 = torch.ops.npu._npu_silent_check_v2
torch_npu.npu_lstm_data_backward = torch.ops.npu.npu_lstm_data_backward
torch_npu.npu_mm_reduce_scatter_base = torch.ops.npu.npu_mm_reduce_scatter_base
torch_npu._amp_foreach_non_finite_check = torch.ops.npu._amp_foreach_non_finite_check
torch_npu.one_ = torch.ops.npu.one_
torch_npu.npu_mish = torch.ops.npu.npu_mish
torch_npu.npu_conv2d = torch.ops.npu.npu_conv2d
torch_npu.get_npu_format = torch.ops.npu.get_npu_format
torch_npu.npu_quant_scatter = torch.ops.npu.npu_quant_scatter
torch_npu.npu_rotated_box_decode = torch.ops.npu.npu_rotated_box_decode
torch_npu.npu_sign_bits_pack = torch.ops.npu.npu_sign_bits_pack
torch_npu.npu_fused_infer_attention_score = torch.ops.npu.npu_fused_infer_attention_score
torch_npu.npu_prompt_flash_attention = torch.ops.npu.npu_prompt_flash_attention
torch_npu.empty_with_swapped_memory = torch.ops.npu.empty_with_swapped_memory
torch_npu.dropout_with_byte_mask = torch.ops.npu.dropout_with_byte_mask
torch_npu.npu_confusion_transpose = torch.ops.npu.npu_confusion_transpose
torch_npu.npu_nsa_compress = torch.ops.npu.npu_nsa_compress
torch_npu.npu_alltoallv_gmm = torch.ops.npu.npu_alltoallv_gmm
torch_npu.npu_group_norm_swish = torch.ops.npu.npu_group_norm_swish
torch_npu.npu_normalize_batch = torch.ops.npu.npu_normalize_batch
torch_npu.npu_moe_distribute_combine = torch.ops.npu.npu_moe_distribute_combine
torch_npu.npu_add_rms_norm_cast = torch.ops.npu.npu_add_rms_norm_cast
torch_npu.npu_deep_norm_backward = torch.ops.npu.npu_deep_norm_backward
torch_npu.npu_mish_backward = torch.ops.npu.npu_mish_backward
torch_npu._npu_fused_infer_attention_score_get_max_workspace = torch.ops.npu._npu_fused_infer_attention_score_get_max_workspace
torch_npu.fft_r2c_backward = torch.ops.npu.fft_r2c_backward
torch_npu.npu_group_norm_swish_grad = torch.ops.npu.npu_group_norm_swish_grad
torch_npu.npu_format_cast = torch.ops.npu.npu_format_cast
torch_npu.npu_fused_attention_qkv_grad = torch.ops.npu.npu_fused_attention_qkv_grad
torch_npu.npu_get_float_status = torch.ops.npu.npu_get_float_status
torch_npu.slow_conv_transpose2d_backward = torch.ops.npu.slow_conv_transpose2d_backward
torch_npu.npu_silu_ = torch.ops.npu.npu_silu_
torch_npu.npu_dynamic_quant = torch.ops.npu.npu_dynamic_quant
torch_npu.npu_dtype_cast_ = torch.ops.npu.npu_dtype_cast_
torch_npu.npu_sparse_paged_fusion_attention = torch.ops.npu.npu_sparse_paged_fusion_attention
torch_npu.npu_quant_scatter_ = torch.ops.npu.npu_quant_scatter_
torch_npu.unsafe_empty_with_format = torch.ops.npu.unsafe_empty_with_format
torch_npu.npu_gather_backward = torch.ops.npu.npu_gather_backward
torch_npu.npu_multi_head_attention = torch.ops.npu.npu_multi_head_attention
torch_npu.scatter_update = torch.ops.npu.scatter_update
torch_npu.npu_alloc_float_status = torch.ops.npu.npu_alloc_float_status
torch_npu.npu_attn_softmax_backward_ = torch.ops.npu.npu_attn_softmax_backward_
torch_npu.npu_softmax_cross_entropy_with_logits = torch.ops.npu.npu_softmax_cross_entropy_with_logits
torch_npu.npu_change_data_ptr = torch.ops.npu.npu_change_data_ptr
torch_npu.npu_rotary_mul_backward = torch.ops.npu.npu_rotary_mul_backward
torch_npu.npu_conv3d = torch.ops.npu.npu_conv3d
torch_npu.npu_gmm_alltoallv = torch.ops.npu.npu_gmm_alltoallv
torch_npu.npu_sign_bits_unpack = torch.ops.npu.npu_sign_bits_unpack
torch_npu.npu_moe_gating_top_k = torch.ops.npu.npu_moe_gating_top_k
torch_npu.npu_multi_head_attention_v2 = torch.ops.npu.npu_multi_head_attention_v2
torch_npu.npu_moe_init_routing = torch.ops.npu.npu_moe_init_routing
torch_npu.npu_grouped_matmul = torch.ops.npu.npu_grouped_matmul
torch_npu.npu_scatter = torch.ops.npu.npu_scatter
torch_npu.npu_lstm_cell = torch.ops.npu.npu_lstm_cell
torch_npu.npu_moe_re_routing = torch.ops.npu.npu_moe_re_routing
torch_npu.npu_multi_head_attention_backward = torch.ops.npu.npu_multi_head_attention_backward
torch_npu.npu_multi_head_attention_v2_grad = torch.ops.npu.npu_multi_head_attention_v2_grad
torch_npu.npu_clear_float_status = torch.ops.npu.npu_clear_float_status
torch_npu.npu_bert_apply_adam = torch.ops.npu.npu_bert_apply_adam
torch_npu.npu_diou_backward = torch.ops.npu.npu_diou_backward
torch_npu.npu_grid_assign_positive = torch.ops.npu.npu_grid_assign_positive
torch_npu.npu_prefetch = torch.ops.npu.npu_prefetch
torch_npu.npu_diou = torch.ops.npu.npu_diou
torch_npu.npu_deformable_conv2dbk = torch.ops.npu.npu_deformable_conv2dbk
torch_npu.npu_batch_gather_matmul = torch.ops.npu.npu_batch_gather_matmul
torch_npu.npu_dequant_rope_quant_kvcache = torch.ops.npu.npu_dequant_rope_quant_kvcache
torch_npu.npu_dropout_with_add_softmax_backward = torch.ops.npu.npu_dropout_with_add_softmax_backward
torch_npu.npu_kronecker_quant = torch.ops.npu.npu_kronecker_quant
torch_npu.npu_convert_weight_to_int4pack = torch.ops.npu.npu_convert_weight_to_int4pack
torch_npu.npu_gru = torch.ops.npu.npu_gru
torch_npu.npu_scaled_masked_softmax_backward = torch.ops.npu.npu_scaled_masked_softmax_backward
torch_npu.npu_dtype_cast_backward = torch.ops.npu.npu_dtype_cast_backward
torch_npu.l1_loss_backward = torch.ops.npu.l1_loss_backward
torch_npu.npu_roi_align = torch.ops.npu.npu_roi_align
torch_npu.npu_lstm = torch.ops.npu.npu_lstm
torch_npu._npu_silent_check = torch.ops.npu._npu_silent_check
torch_npu.npu_indexing = torch.ops.npu.npu_indexing
torch_npu.npu_min_backward = torch.ops.npu.npu_min_backward
torch_npu.npu_transpose_batchmatmul = torch.ops.npu.npu_transpose_batchmatmul
torch_npu.npu_bmm_v2_mat1_backward = torch.ops.npu.npu_bmm_v2_mat1_backward
torch_npu.npu_fusion_attention_grad = torch.ops.npu.npu_fusion_attention_grad
torch_npu.npu_deformable_conv2d = torch.ops.npu.npu_deformable_conv2d
torch_npu.npu_moe_distribute_combine_add_rms_norm = torch.ops.npu.npu_moe_distribute_combine_add_rms_norm
torch_npu.npu_layer_norm_eval = torch.ops.npu.npu_layer_norm_eval
torch_npu.npu_add_layer_norm_backward = torch.ops.npu.npu_add_layer_norm_backward
torch_npu.npu_all_gather_base_mm = torch.ops.npu.npu_all_gather_base_mm
torch_npu._npu_format_cast = torch.ops.npu._npu_format_cast
torch_npu.npu_apply_rotary_pos_emb = torch.ops.npu.npu_apply_rotary_pos_emb
torch_npu.npu_group_norm_silu = torch.ops.npu.npu_group_norm_silu
torch_npu.npu_silu_backward = torch.ops.npu.npu_silu_backward
torch_npu.npu_rms_norm_backward = torch.ops.npu.npu_rms_norm_backward
torch_npu.npu_quant_grouped_matmul_dequant = torch.ops.npu.npu_quant_grouped_matmul_dequant
torch_npu.slow_conv_dilated2d_backward = torch.ops.npu.slow_conv_dilated2d_backward
torch_npu.npu_ps_roi_pooling = torch.ops.npu.npu_ps_roi_pooling
torch_npu.npu_scaled_masked_softmax = torch.ops.npu.npu_scaled_masked_softmax
torch_npu.npu_scatter_list = torch.ops.npu.npu_scatter_list
torch_npu.npu_scatter_nd_update_ = torch.ops.npu.npu_scatter_nd_update_
torch_npu.npu_sub_sample = torch.ops.npu.npu_sub_sample
torch_npu.npu_transpose = torch.ops.npu.npu_transpose
torch_npu.npu_attn_softmax_ = torch.ops.npu.npu_attn_softmax_
torch_npu.npu_moe_finalize_routing = torch.ops.npu.npu_moe_finalize_routing
torch_npu.copy_memory_ = torch.ops.npu.copy_memory_
torch_npu.npu_batch_nms = torch.ops.npu.npu_batch_nms
torch_npu.npu_linear_backward = torch.ops.npu.npu_linear_backward
torch_npu.npu_scatter_list_ = torch.ops.npu.npu_scatter_list_
torch_npu.npu_interleave_rope = torch.ops.npu.npu_interleave_rope
torch_npu.npu_batch_gather_matmul_ = torch.ops.npu.npu_batch_gather_matmul_
torch_npu.npu_nms_v4 = torch.ops.npu.npu_nms_v4
torch_npu.npu_one_hot = torch.ops.npu.npu_one_hot
torch_npu.npu_quant_matmul = torch.ops.npu.npu_quant_matmul
torch_npu.npu_add_layer_norm = torch.ops.npu.npu_add_layer_norm
torch_npu.npu_moe_eplb_update_expert = torch.ops.npu.npu_moe_eplb_update_expert
torch_npu.npu_kv_rmsnorm_rope_cache = torch.ops.npu.npu_kv_rmsnorm_rope_cache
torch_npu.npu_ffn = torch.ops.npu.npu_ffn
torch_npu.npu_fusion_attention_grad_v2 = torch.ops.npu.npu_fusion_attention_grad_v2
torch_npu.npu_moe_distribute_combine_v2 = torch.ops.npu.npu_moe_distribute_combine_v2
torch_npu._npu_distribute_barrier = torch.ops.npu._npu_distribute_barrier
torch_npu.npu_bounding_box_decode = torch.ops.npu.npu_bounding_box_decode
torch_npu.npu_layernorm_grad = torch.ops.npu.npu_layernorm_grad
torch_npu.npu_mm_all_reduce_base = torch.ops.npu.npu_mm_all_reduce_base
torch_npu.npu_gru_backward = torch.ops.npu.npu_gru_backward
torch_npu.npu_rotated_box_encode = torch.ops.npu.npu_rotated_box_encode
torch_npu.npu_rope_quant_kvcache = torch.ops.npu.npu_rope_quant_kvcache
torch_npu.npu_scatter_nd_update = torch.ops.npu.npu_scatter_nd_update
torch_npu.npu_gather_sparse_index = torch.ops.npu.npu_gather_sparse_index
torch_npu.npu_pad = torch.ops.npu.npu_pad
torch_npu.npu_grouped_matmul_swiglu_quant = torch.ops.npu.npu_grouped_matmul_swiglu_quant
torch_npu.npu_grouped_matmul_finalize_routing = torch.ops.npu.npu_grouped_matmul_finalize_routing
torch_npu.npu_max_backward = torch.ops.npu.npu_max_backward
torch_npu.npu_cent_select = torch.ops.npu.npu_cent_select
torch_npu.npu_gelu = torch.ops.npu.npu_gelu
torch_npu.npu_moe_distribute_dispatch = torch.ops.npu.npu_moe_distribute_dispatch
torch_npu.npu_yolo_boxes_encode = torch.ops.npu.npu_yolo_boxes_encode
torch_npu.npu_deep_norm = torch.ops.npu.npu_deep_norm
torch_npu.npu_giou = torch.ops.npu.npu_giou
torch_npu.matmul_double_backward = torch.ops.npu.matmul_double_backward
torch_npu.npu_rms_norm = torch.ops.npu.npu_rms_norm
torch_npu.scatter_update_ = torch.ops.npu.scatter_update_
torch_npu.npu_top_k_top_p = torch.ops.npu.npu_top_k_top_p
torch_npu.npu_convolution_backward = torch.ops.npu.npu_convolution_backward
torch_npu.npu_min = torch.ops.npu.npu_min
torch_npu.npu_mla_prolog_v2 = torch.ops.npu.npu_mla_prolog_v2
torch_npu.npu_ptiou = torch.ops.npu.npu_ptiou
torch_npu.npu_sort_v2 = torch.ops.npu.npu_sort_v2
torch_npu.npu_apply_adam = torch.ops.npu.npu_apply_adam
torch_npu.npu_conv_transpose3d_backward = torch.ops.npu.npu_conv_transpose3d_backward
torch_npu.npu_masked_fill_range = torch.ops.npu.npu_masked_fill_range
torch_npu.npu_softmax_cross_entropy_with_logits_backward = torch.ops.npu.npu_softmax_cross_entropy_with_logits_backward
torch_npu.npu_advance_step_flashattn = torch.ops.npu.npu_advance_step_flashattn
torch_npu.batch_norm_gather_stats_update = torch.ops.npu.batch_norm_gather_stats_update
torch_npu.npu_format_cast_ = torch.ops.npu.npu_format_cast_
torch_npu.npu_anti_quant = torch.ops.npu.npu_anti_quant
torch_npu.npu_fast_gelu = torch.ops.npu.npu_fast_gelu
torch_npu.npu_silu = torch.ops.npu.npu_silu
torch_npu.npu_geglu_grad = torch.ops.npu.npu_geglu_grad
torch_npu._npu_ciou = torch.ops.npu._npu_ciou
torch_npu.npu_giou_backward = torch.ops.npu.npu_giou_backward
torch_npu.npu_moe_compute_expert_tokens = torch.ops.npu.npu_moe_compute_expert_tokens
torch_npu.kl_div_backward = torch.ops.npu.kl_div_backward
torch_npu.npu_add_rms_norm = torch.ops.npu.npu_add_rms_norm
torch_npu.npu_fusion_attention_v2 = torch.ops.npu.npu_fusion_attention_v2
torch_npu.npu_dropout_backward = torch.ops.npu.npu_dropout_backward
torch_npu.fft_c2r_backward = torch.ops.npu.fft_c2r_backward
torch_npu.npu_ifmr = torch.ops.npu.npu_ifmr
torch_npu.npu_linear = torch.ops.npu.npu_linear
torch_npu.npu_fusion_attention = torch.ops.npu.npu_fusion_attention
torch_npu.npu_nsa_compress_attention = torch.ops.npu.npu_nsa_compress_attention
torch_npu.npu_dequant_swiglu_quant = torch.ops.npu.npu_dequant_swiglu_quant
torch_npu.npu_cross_entropy_loss = torch.ops.npu.npu_cross_entropy_loss
torch_npu.npu_nsa_select_attention_grad = torch.ops.npu.npu_nsa_select_attention_grad
torch_npu.npu_conv_transpose2d_backward = torch.ops.npu.npu_conv_transpose2d_backward
torch_npu._npu_dropout = torch.ops.npu._npu_dropout
torch_npu.npu_sparse_paged_attention = torch.ops.npu.npu_sparse_paged_attention
torch_npu.npu_nsa_compress_grad = torch.ops.npu.npu_nsa_compress_grad
torch_npu.npu_our_incre_flash_attention = torch.ops.npu.npu_our_incre_flash_attention
torch_npu.npu_lstm_backward = torch.ops.npu.npu_lstm_backward
torch_npu.npu_slice = torch.ops.npu.npu_slice
torch_npu.npu_quant_conv2d = torch.ops.npu.npu_quant_conv2d
torch_npu._npu_dropout_gen_mask = torch.ops.npu._npu_dropout_gen_mask
