#ifndef TORCH_NPU_CSRC_ATEN_CUSTOM_FUNCTIONS
#define TORCH_NPU_CSRC_ATEN_CUSTOM_FUNCTIONS

#include <ATen/ATen.h>

namespace at_npu {
namespace native {
namespace custom_ops {

int64_t npu_change_data_ptr(const at::Tensor & dst, const at::Tensor & src, int64_t index);
int64_t get_npu_format(const at::Tensor & self);
at::Tensor npu_format_cast(const at::Tensor & self, const at::Tensor & dst);
at::Tensor & npu_format_cast_(at::Tensor & self, int64_t acl_format);
at::Tensor & npu_format_cast_(at::Tensor & self, const at::Tensor & src);
at::Tensor empty_with_format(at::IntArrayRef size, ::std::optional<at::ScalarType> dtype={}, ::std::optional<at::Layout> layout={}, ::std::optional<at::Device> device={}, ::std::optional<bool> pin_memory={}, int64_t acl_format=2, ::std::optional<int64_t> base_addr_aligned_kb=::std::nullopt);
at::Tensor unsafe_empty_with_format(at::IntArrayRef size, ::std::optional<at::ScalarType> dtype={}, ::std::optional<at::Layout> layout={}, ::std::optional<at::Device> device={}, ::std::optional<bool> pin_memory={}, int64_t acl_format=2, bool keep_format=false);
at::Tensor empty_with_format(at::IntArrayRef size, ::std::optional<at::DimnameList> names, ::std::optional<at::ScalarType> dtype={}, ::std::optional<at::Layout> layout={}, ::std::optional<at::Device> device={}, ::std::optional<bool> pin_memory={}, int64_t acl_format=2);
at::Tensor & copy_memory_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
int64_t get_storage_size(const at::Tensor & self);
at::Tensor npu_format_cast(const at::Tensor & self, int64_t acl_format);
at::Tensor _npu_format_cast(const at::Tensor & self, int64_t acl_format);
at::Tensor empty_with_swapped_memory(at::IntArrayRef size, ::std::optional<at::ScalarType> dtype=::std::nullopt, ::std::optional<at::Device> device=::std::nullopt);
at::Tensor npu_gather_backward(const at::Tensor & grad, c10::SymIntArrayRef self_size, int64_t dim, const at::Tensor & index, bool sparse_grad);
bool _amp_foreach_non_finite_check(at::TensorList scaled_grads);
at::Tensor npu_gelu(const at::Tensor & self, c10::string_view approximate="none");
at::Tensor npu_gelu_backward(const at::Tensor & grad_output, const at::Tensor & self, c10::string_view approximate="none");
::std::tuple<at::Tensor,at::Tensor> _conv_depthwise2d_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & weight, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, ::std::array<bool,2> output_mask);
::std::tuple<at::Tensor,at::Tensor> _dropout_with_byte_mask(const at::Tensor & self, double p);
at::Tensor _dropout_with_byte_mask_backward(const at::Tensor & grad_output, const at::Tensor & mask, double p);
::std::tuple<at::Tensor,at::Tensor> _npu_ciou(const at::Tensor & self, const at::Tensor & gtboxes, bool trans=false, bool is_cross=true, int64_t mode=0, bool atan_sub_flag=false);
::std::tuple<at::Tensor,at::Tensor> _npu_dropout(const at::Tensor & self, double p);
at::Tensor _npu_dropout_gen_mask(const at::Tensor & self, at::IntArrayRef size, double p, int64_t seed, int64_t offset, ::std::optional<bool> parallel=true, ::std::optional<bool> sync=::std::nullopt);
at::Tensor _npu_silent_check(at::Tensor & input_grad, const at::Tensor & val, at::Tensor & pre_val, at::Tensor & min_val, at::Tensor & max_val, const at::Tensor & val_counter, int64_t c_min_steps, double c_thresh_l1, double c_coeff_l1, double c_thresh_l2, double c_coeff_l2);
at::Tensor _npu_silent_check_v2(const at::Tensor & val, at::Tensor & input_grad, at::Tensor & sfda, at::Tensor & step, int64_t c_min_steps, double c_thresh_l1, double c_coeff_l1, double c_thresh_l2, double c_coeff_l2, int64_t npu_asd_detect);
at::Tensor _npu_silent_check_v3(const at::Tensor & val, at::Tensor & input_grad, at::Tensor & step, at::Tensor & max, at::Tensor & avg, double c_thresh_l1, double c_thresh_l2, double betal, int64_t npu_asd_detect);
::std::tuple<at::Tensor,at::Tensor> batch_norm_gather_stats_update(const at::Tensor & input, const at::Tensor & mean, const at::Tensor & invstd, const ::std::optional<at::Tensor> & running_mean, const ::std::optional<at::Tensor> & running_var, double momentum, double eps, const at::Tensor & counts);
::std::tuple<at::Tensor,at::Tensor> batch_norm_reduce(const at::Tensor & input, double eps);
at::Tensor dropout_with_byte_mask(const at::Tensor & self, double p, bool train);
at::Tensor fast_gelu(const at::Tensor & self);
at::Tensor kl_div_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & target, int64_t reduction=at::Reduction::Mean, bool log_target=false);
at::Tensor l1_loss_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & target, int64_t reduction);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> slow_conv_dilated2d_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & weight, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, ::std::array<bool,3> output_mask);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> matmul_double_backward(const ::std::optional<at::Tensor> & grad_self, const ::std::optional<at::Tensor> & grad_other, const at::Tensor & grad_out, const at::Tensor & self, const at::Tensor & other, ::std::array<bool,3> mask);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_add_layer_norm(const at::Tensor & x1, const at::Tensor & x2, const at::Tensor & gamma, const at::Tensor & beta, double epsilon=1e-05, bool additional_output=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_add_layer_norm_backward(const ::std::optional<at::Tensor> & dy_opt, const at::Tensor & x1, const at::Tensor & x2, const at::Tensor & rstd, const at::Tensor & mean, const at::Tensor & gamma, const ::std::optional<at::Tensor> & dsum_opt);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_add_rms_norm(const at::Tensor & x1, const at::Tensor & x2, const at::Tensor & gamma, double epsilon=1e-06);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_add_rms_norm_cast(const at::Tensor & x1, const at::Tensor & x2, const at::Tensor & gamma, double epsilon=1e-06);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_add_rms_norm_quant(const at::Tensor & x1, const at::Tensor & x2, const at::Tensor & gamma, const at::Tensor & scales1, const ::std::optional<at::Tensor> & zero_points1, const ::std::optional<at::Tensor> & scales2={}, const ::std::optional<at::Tensor> & zero_points2={}, int64_t axis=-1, double epsilon=1e-06, bool div_mode=true);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_alltoallv_gmm(const at::Tensor & gmm_x, const at::Tensor & gmm_weight, c10::string_view hcom, int64_t ep_world_size, at::IntArrayRef send_counts, at::IntArrayRef recv_counts, const ::std::optional<at::Tensor> & send_counts_tensor={}, const ::std::optional<at::Tensor> & recv_counts_tensor={}, const ::std::optional<at::Tensor> & mm_x={}, const ::std::optional<at::Tensor> & mm_weight={}, bool trans_gmm_weight=false, bool trans_mm_weight=false, bool permute_out_flag=false);
::std::tuple<at::Tensor,at::Tensor> npu_gmm_alltoallv(const at::Tensor & gmm_x, const at::Tensor & gmm_weight, c10::string_view hcom, int64_t ep_world_size, at::IntArrayRef send_counts, at::IntArrayRef recv_counts, const ::std::optional<at::Tensor> & send_counts_tensor={}, const ::std::optional<at::Tensor> & recv_counts_tensor={}, const ::std::optional<at::Tensor> & mm_x={}, const ::std::optional<at::Tensor> & mm_weight={}, bool trans_gmm_weight=false, bool trans_mm_weight=false);
::std::tuple<at::Tensor,at::Tensor> npu_all_gather_base_mm(const at::Tensor & self, const at::Tensor & x2, c10::string_view hcom, int64_t world_size, const ::std::optional<at::Tensor> & bias={}, int64_t gather_index=0, bool gather_output=true, int64_t comm_turn=0);
at::Tensor npu_alloc_float_status(const at::Tensor & self);
at::Tensor npu_anchor_response_flags(const at::Tensor & self, at::IntArrayRef featmap_size, at::IntArrayRef stride, int64_t num_base_anchors);
at::Tensor npu_anti_quant(const at::Tensor & x, const at::Tensor & scale, const ::std::optional<at::Tensor> & offset={}, ::std::optional<at::ScalarType> dst_dtype=::std::nullopt, ::std::optional<at::ScalarType> src_dtype=::std::nullopt);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_apply_adam(const at::Scalar & beta1_power, const at::Scalar & beta2_power, const at::Scalar & lr, const at::Scalar & beta1, const at::Scalar & beta2, const at::Scalar & epsilon, const at::Tensor & grad, ::std::optional<bool> use_locking, ::std::optional<bool> use_nesterov);
::std::tuple<at::Tensor &,at::Tensor &,at::Tensor &> npu_apply_adam_out(const at::Scalar & beta1_power, const at::Scalar & beta2_power, const at::Scalar & lr, const at::Scalar & beta1, const at::Scalar & beta2, const at::Scalar & epsilon, const at::Tensor & grad, ::std::optional<bool> use_locking, ::std::optional<bool> use_nesterov, at::Tensor & var, at::Tensor & m, at::Tensor & v);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_apply_adam_w(const at::Scalar & beta1_power, const at::Scalar & beta2_power, const at::Scalar & lr, const at::Scalar & weight_decay, const at::Scalar & beta1, const at::Scalar & beta2, const at::Scalar & epsilon, const at::Tensor & grad, const ::std::optional<at::Tensor> & max_grad_norm, ::std::optional<bool> amsgrad, ::std::optional<bool> maximize);
::std::tuple<at::Tensor &,at::Tensor &,at::Tensor &> npu_apply_adam_w_out(const at::Scalar & beta1_power, const at::Scalar & beta2_power, const at::Scalar & lr, const at::Scalar & weight_decay, const at::Scalar & beta1, const at::Scalar & beta2, const at::Scalar & epsilon, const at::Tensor & grad, const ::std::optional<at::Tensor> & max_grad_norm, ::std::optional<bool> amsgrad, ::std::optional<bool> maximize, at::Tensor & var, at::Tensor & m, at::Tensor & v);
::std::tuple<at::Tensor,at::Tensor> npu_apply_rotary_pos_emb(const at::Tensor & query, const at::Tensor & key, const at::Tensor & cos, const at::Tensor & sin, c10::string_view layout="BSH");
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_kv_rmsnorm_rope_cache(const at::Tensor & kv, const at::Tensor & gamma, const at::Tensor & cos, const at::Tensor & sin, const at::Tensor & index, const at::Tensor & k_cache, const at::Tensor & ckv_cache, const ::std::optional<at::Tensor> & k_rope_scale={}, const ::std::optional<at::Tensor> & c_kv_scale={}, const ::std::optional<at::Tensor> & k_rope_offset={}, const ::std::optional<at::Tensor> & c_kv_offset={}, double epsilon=1e-5, c10::string_view cache_mode="Norm", bool is_output_kv=false);
at::Tensor npu_batch_gather_matmul(const at::Tensor & self, const at::Tensor & x, const at::Tensor & weight_b, const at::Tensor & indices, const ::std::optional<at::Tensor> & weight_a={}, int64_t layer_idx=0, double scale=1e-3, int64_t y_offset=0, int64_t y_slice_size=-1);
at::Tensor & npu_batch_gather_matmul_(at::Tensor & self, const at::Tensor & x, const at::Tensor & weight_b, const at::Tensor & indices, const ::std::optional<at::Tensor> & weight_a={}, int64_t layer_idx=0, double scale=1e-3, int64_t y_offset=0, int64_t y_slice_size=-1);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_batch_nms(const at::Tensor & self, const at::Tensor & scores, double score_threshold, double iou_threshold, int64_t max_size_per_class, int64_t max_total_size, bool change_coordinate_frame=false, bool transpose_box=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_bert_apply_adam(const at::Scalar & lr, const at::Scalar & beta1, const at::Scalar & beta2, const at::Scalar & epsilon, const at::Tensor & grad, const at::Scalar & max_grad_norm, const at::Scalar & global_grad_norm, const at::Scalar & weight_decay, const ::std::optional<at::Scalar> & step_size=::std::nullopt, int64_t adam_mode=0);
::std::tuple<at::Tensor &,at::Tensor &,at::Tensor &> npu_bert_apply_adam_out(const at::Scalar & lr, const at::Scalar & beta1, const at::Scalar & beta2, const at::Scalar & epsilon, const at::Tensor & grad, const at::Scalar & max_grad_norm, const at::Scalar & global_grad_norm, const at::Scalar & weight_decay, const ::std::optional<at::Scalar> & step_size, int64_t adam_mode, at::Tensor & var, at::Tensor & m, at::Tensor & v);
at::Tensor npu_binary_cross_entropy_with_logits_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & target, const ::std::optional<at::Tensor> & weight_opt, const ::std::optional<at::Tensor> & pos_weight_opt, int64_t reduction);
at::Tensor npu_bmmV2(const at::Tensor & self, const at::Tensor & mat2, at::IntArrayRef output_sizes);
at::Tensor npu_bmm_v2_mat1_backward(const at::Tensor & grad, const at::Tensor & mat1, const at::Tensor & mat2, c10::SymIntArrayRef size);
at::Tensor npu_bmm_v2_mat2_backward(const at::Tensor & grad, const at::Tensor & mat1, const at::Tensor & mat2, c10::SymIntArrayRef size);
at::Tensor npu_bounding_box_decode(const at::Tensor & rois, const at::Tensor & deltas, double means0, double means1, double means2, double means3, double stds0, double stds1, double stds2, double stds3, at::IntArrayRef max_shape, double wh_ratio_clip);
at::Tensor npu_bounding_box_encode(const at::Tensor & anchor_box, const at::Tensor & ground_truth_box, double means0, double means1, double means2, double means3, double stds0, double stds1, double stds2, double stds3);
at::Tensor npu_broadcast(const at::Tensor & self, at::IntArrayRef size);
at::Tensor & npu_broadcast_out(const at::Tensor & self, at::IntArrayRef size, at::Tensor & out);
at::Tensor npu_ciou(const at::Tensor & self, const at::Tensor & gtboxes, bool trans=false, bool is_cross=true, int64_t mode=0, bool atan_sub_flag=false);
::std::tuple<at::Tensor,at::Tensor> npu_ciou_backward(const at::Tensor & grad, const at::Tensor & bboxes, const at::Tensor & gtboxes, const ::std::optional<at::Tensor> & atan_sub, bool trans=false, bool is_cross=true, int64_t mode=0);
at::Tensor npu_clear_float_status(const at::Tensor & self, int64_t mode=0);
at::Tensor npu_confusion_transpose(const at::Tensor & self, at::IntArrayRef perm, at::IntArrayRef shape, bool transpose_first);
at::Tensor npu_confusion_transpose_backward(const at::Tensor & grad, at::IntArrayRef perm, c10::SymIntArrayRef shape, bool transpose_first);
at::Tensor npu_conv2d(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, int64_t groups);
at::Tensor & npu_conv2d_out(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, int64_t groups, at::Tensor & out);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_conv2d_backward(const at::Tensor & input, const at::Tensor & grad_output, const at::Tensor & weight, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, int64_t groups, ::std::array<bool,3> output_mask);
at::Tensor npu_conv3d(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, int64_t groups);
at::Tensor & npu_conv3d_out(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, int64_t groups, at::Tensor & out);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_conv3d_backward(const at::Tensor & input, const at::Tensor & grad, const at::Tensor & weight, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, int64_t groups, ::std::array<bool,3> output_mask);
at::Tensor npu_conv_transpose2d(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias, at::IntArrayRef padding, at::IntArrayRef output_padding, at::IntArrayRef stride, at::IntArrayRef dilation, int64_t groups);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_conv_transpose2d_backward(const at::Tensor & input, const at::Tensor & grad_output, const at::Tensor & weight, at::IntArrayRef padding, at::IntArrayRef output_padding, at::IntArrayRef stride, at::IntArrayRef dilation, int64_t groups, ::std::array<bool,3> output_mask);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_conv_transpose3d_backward(const at::Tensor & input, const at::Tensor & grad_output, const at::Tensor & weight, at::IntArrayRef padding, at::IntArrayRef output_padding, at::IntArrayRef stride, at::IntArrayRef dilation, int64_t groups, ::std::array<bool,3> output_mask);
at::Tensor npu_convert_weight_to_int4pack(const at::Tensor & weight, int64_t inner_k_tiles=0);
at::Tensor npu_convolution(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, int64_t groups);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_convolution_backward(const at::Tensor & input, const at::Tensor & grad_output, const at::Tensor & weight, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, int64_t groups, ::std::array<bool,3> output_mask);
at::Tensor npu_convolution_transpose(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias, at::IntArrayRef padding, at::IntArrayRef output_padding, at::IntArrayRef stride, at::IntArrayRef dilation, int64_t groups);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_convolution_transpose_backward(const at::Tensor & input, const at::Tensor & grad, const at::Tensor & weight, at::IntArrayRef padding, at::IntArrayRef output_padding, at::IntArrayRef stride, at::IntArrayRef dilation, int64_t groups, ::std::array<bool,3> grad_input_mask);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_deep_norm(const at::Tensor & x, const at::Tensor & gx, const at::Tensor & beta, const at::Tensor & gamma, double alpha=0.3, double epsilon=1e-06);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_deep_norm_backward(const at::Tensor & dy, const at::Tensor & x, const at::Tensor & gx, const at::Tensor & gamma, const at::Tensor & mean, const at::Tensor & rstd, double alpha=0.3);
::std::tuple<at::Tensor,at::Tensor> npu_deformable_conv2d(const at::Tensor & input, const at::Tensor & weight, const at::Tensor & offset, const ::std::optional<at::Tensor> & bias, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation={1,1,1,1}, int64_t groups=1, int64_t deformable_groups=1, bool modulated=true);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_deformable_conv2dbk(const at::Tensor & input, const at::Tensor & grad_output, const at::Tensor & offset_out, const at::Tensor & weight, const at::Tensor & offset, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation={1,1,1,1}, int64_t groups=1, int64_t deformable_groups=1, bool modulated=true);
at::Tensor npu_diou(const at::Tensor & self, const at::Tensor & gtboxes, bool trans=false, bool is_cross=false, int64_t mode=0);
::std::tuple<at::Tensor,at::Tensor> npu_diou_backward(const at::Tensor & grad, const at::Tensor & bboxes, const at::Tensor & gtboxes, bool trans=false, bool is_cross=false, int64_t mode=0);
at::Tensor npu_dropout_backward(const at::Tensor & grad_output, const at::Tensor & mask, double p);
::std::tuple<at::Tensor,at::Tensor> npu_dropout_do_mask(const at::Tensor & self, const at::Tensor & mask, double p);
at::Tensor npu_dropout_gen_mask(at::IntArrayRef size, double p, ::std::optional<at::ScalarType> dtype={}, ::std::optional<at::Layout> layout={}, ::std::optional<at::Device> device={}, ::std::optional<bool> pin_memory={});
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_dropout_with_add_softmax(const at::Tensor & self, const at::Tensor & x1, const at::Scalar & alpha, double prob, int64_t dim);
::std::tuple<at::Tensor,at::Tensor> npu_dropout_with_add_softmax_backward(const at::Tensor & grad, const at::Tensor & mask, const at::Tensor & softmax_out, const at::Scalar & alpha, double prob, int64_t dim);
at::Tensor npu_dtype_cast(const at::Tensor & self, at::ScalarType dtype);
at::Tensor & npu_dtype_cast_(at::Tensor & self, const at::Tensor & src);
at::Tensor npu_dtype_cast_backward(const at::Tensor & grad, at::ScalarType dtype);
::std::tuple<at::Tensor,at::Tensor> npu_dynamic_quant(const at::Tensor & input, const ::std::optional<at::Tensor> & smooth_scales={}, const ::std::optional<at::Tensor> & group_index={}, ::std::optional<at::ScalarType> dst_type=::std::nullopt);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_dynamic_quant_asymmetric(const at::Tensor & input, const ::std::optional<at::Tensor> & smooth_scales={}, const ::std::optional<at::Tensor> & group_index={}, ::std::optional<at::ScalarType> dst_type=::std::nullopt);
at::Tensor npu_fast_gelu(const at::Tensor & self);
at::Tensor npu_fast_gelu_backward(const at::Tensor & grad, const at::Tensor & self);
at::Tensor npu_ffn(const at::Tensor & x, const at::Tensor & weight1, const at::Tensor & weight2, c10::string_view activation, at::OptionalIntArrayRef expert_tokens=::std::nullopt, at::OptionalIntArrayRef expert_tokens_index=::std::nullopt, const ::std::optional<at::Tensor> & bias1={}, const ::std::optional<at::Tensor> & bias2={}, const ::std::optional<at::Tensor> & scale={}, const ::std::optional<at::Tensor> & offset={}, const ::std::optional<at::Tensor> & deq_scale1={}, const ::std::optional<at::Tensor> & deq_scale2={}, const ::std::optional<at::Tensor> & antiquant_scale1={}, const ::std::optional<at::Tensor> & antiquant_scale2={}, const ::std::optional<at::Tensor> & antiquant_offset1={}, const ::std::optional<at::Tensor> & antiquant_offset2={}, ::std::optional<int64_t> inner_precise=::std::nullopt, ::std::optional<at::ScalarType> output_dtype=::std::nullopt);
at::Tensor npu_fused_attention_score(const at::Tensor & query_layer, const at::Tensor & key_layer, const at::Tensor & value_layer, const at::Tensor & attention_mask, const at::Scalar & scale, double keep_prob, bool query_transpose=false, bool key_transpose=false, bool bmm_score_transpose_a=false, bool bmm_score_transpose_b=false, bool value_transpose=false, bool dx_transpose=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_fused_attention_score_backward(const at::Tensor & grad_output, const at::Tensor & softmax_output, const at::Tensor & query_layer, const at::Tensor & key_layer, const at::Tensor & value_layer, const at::Tensor & mask, const at::Scalar & scale, double keep_prob, bool query_transpose=false, bool key_transpose=false, bool value_transpose=false, bool dx_transpose=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_fused_attention_score_fwd(const at::Tensor & query_layer, const at::Tensor & key_layer, const at::Tensor & value_layer, const at::Tensor & attention_mask, const at::Scalar & scale, double keep_prob, bool query_transpose=false, bool key_transpose=false, bool bmm_score_transpose_a=false, bool bmm_score_transpose_b=false, bool value_transpose=false, bool dx_transpose=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_fused_attention_score_grad(const at::Tensor & grad_output, const at::Tensor & softmax_output, const at::Tensor & query_layer, const at::Tensor & key_layer, const at::Tensor & value_layer, const at::Tensor & mask, const at::Scalar & scale, double keep_prob, bool query_transpose=false, bool key_transpose=false, bool value_transpose=false, bool dx_transpose=false);
::std::tuple<at::Tensor,at::Tensor> npu_fused_infer_attention_score(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const ::std::optional<at::Tensor> & pse_shift={}, const ::std::optional<at::Tensor> & atten_mask={}, at::OptionalSymIntArrayRef actual_seq_lengths=::std::nullopt, at::OptionalSymIntArrayRef actual_seq_lengths_kv=::std::nullopt, const ::std::optional<at::Tensor> & dequant_scale1={}, const ::std::optional<at::Tensor> & quant_scale1={}, const ::std::optional<at::Tensor> & dequant_scale2={}, const ::std::optional<at::Tensor> & quant_scale2={}, const ::std::optional<at::Tensor> & quant_offset2={}, const ::std::optional<at::Tensor> & antiquant_scale={}, const ::std::optional<at::Tensor> & antiquant_offset={}, const ::std::optional<at::Tensor> & key_antiquant_scale={}, const ::std::optional<at::Tensor> & key_antiquant_offset={}, const ::std::optional<at::Tensor> & value_antiquant_scale={}, const ::std::optional<at::Tensor> & value_antiquant_offset={}, const ::std::optional<at::Tensor> & block_table={}, const ::std::optional<at::Tensor> & query_padding_size={}, const ::std::optional<at::Tensor> & kv_padding_size={}, const ::std::optional<at::Tensor> & key_shared_prefix={}, const ::std::optional<at::Tensor> & value_shared_prefix={}, at::OptionalSymIntArrayRef actual_shared_prefix_len=::std::nullopt, const ::std::optional<at::Tensor> & query_rope={}, const ::std::optional<at::Tensor> & key_rope={}, const ::std::optional<at::Tensor> & key_rope_antiquant_scale={}, int64_t num_heads=1, double scale=1.0, int64_t pre_tokens=2147483647, int64_t next_tokens=2147483647, c10::string_view input_layout="BSH", int64_t num_key_value_heads=0, int64_t sparse_mode=0, int64_t inner_precise=0, int64_t block_size=0, int64_t antiquant_mode=0, int64_t key_antiquant_mode=0, int64_t value_antiquant_mode=0, bool softmax_lse_flag=false);
::std::tuple<at::Tensor &,at::Tensor &> npu_fused_infer_attention_score_out(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const ::std::optional<at::Tensor> & pse_shift, const ::std::optional<at::Tensor> & atten_mask, at::OptionalSymIntArrayRef actual_seq_lengths, at::OptionalSymIntArrayRef actual_seq_lengths_kv, const ::std::optional<at::Tensor> & dequant_scale1, const ::std::optional<at::Tensor> & quant_scale1, const ::std::optional<at::Tensor> & dequant_scale2, const ::std::optional<at::Tensor> & quant_scale2, const ::std::optional<at::Tensor> & quant_offset2, const ::std::optional<at::Tensor> & antiquant_scale, const ::std::optional<at::Tensor> & antiquant_offset, const ::std::optional<at::Tensor> & key_antiquant_scale, const ::std::optional<at::Tensor> & key_antiquant_offset, const ::std::optional<at::Tensor> & value_antiquant_scale, const ::std::optional<at::Tensor> & value_antiquant_offset, const ::std::optional<at::Tensor> & block_table, const ::std::optional<at::Tensor> & query_padding_size, const ::std::optional<at::Tensor> & kv_padding_size, const ::std::optional<at::Tensor> & key_shared_prefix, const ::std::optional<at::Tensor> & value_shared_prefix, at::OptionalSymIntArrayRef actual_shared_prefix_len, const ::std::optional<at::Tensor> & query_rope, const ::std::optional<at::Tensor> & key_rope, const ::std::optional<at::Tensor> & key_rope_antiquant_scale, int64_t num_heads, double scale, int64_t pre_tokens, int64_t next_tokens, c10::string_view input_layout, int64_t num_key_value_heads, int64_t sparse_mode, int64_t inner_precise, int64_t block_size, int64_t antiquant_mode, int64_t key_antiquant_mode, int64_t value_antiquant_mode, bool softmax_lse_flag, const ::std::optional<at::Tensor> & workspace, at::Tensor & attention_out, at::Tensor & softmax_lse);
at::Tensor _npu_fused_infer_attention_score_get_max_workspace(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const ::std::optional<at::Tensor> & pse_shift={}, const ::std::optional<at::Tensor> & atten_mask={}, at::OptionalSymIntArrayRef actual_seq_lengths=::std::nullopt, at::OptionalSymIntArrayRef actual_seq_lengths_kv=::std::nullopt, const ::std::optional<at::Tensor> & dequant_scale1={}, const ::std::optional<at::Tensor> & quant_scale1={}, const ::std::optional<at::Tensor> & dequant_scale2={}, const ::std::optional<at::Tensor> & quant_scale2={}, const ::std::optional<at::Tensor> & quant_offset2={}, const ::std::optional<at::Tensor> & antiquant_scale={}, const ::std::optional<at::Tensor> & antiquant_offset={}, const ::std::optional<at::Tensor> & key_antiquant_scale={}, const ::std::optional<at::Tensor> & key_antiquant_offset={}, const ::std::optional<at::Tensor> & value_antiquant_scale={}, const ::std::optional<at::Tensor> & value_antiquant_offset={}, const ::std::optional<at::Tensor> & block_table={}, const ::std::optional<at::Tensor> & query_padding_size={}, const ::std::optional<at::Tensor> & kv_padding_size={}, const ::std::optional<at::Tensor> & key_shared_prefix={}, const ::std::optional<at::Tensor> & value_shared_prefix={}, at::OptionalSymIntArrayRef actual_shared_prefix_len=::std::nullopt, const ::std::optional<at::Tensor> & query_rope={}, const ::std::optional<at::Tensor> & key_rope={}, const ::std::optional<at::Tensor> & key_rope_antiquant_scale={}, int64_t num_heads=1, double scale=1.0, int64_t pre_tokens=2147483647, int64_t next_tokens=2147483647, c10::string_view input_layout="BSH", int64_t num_key_value_heads=0, int64_t sparse_mode=0, int64_t inner_precise=0, int64_t block_size=0, int64_t antiquant_mode=0, int64_t key_antiquant_mode=0, int64_t value_antiquant_mode=0, bool softmax_lse_flag=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,int64_t,int64_t,int64_t> npu_fusion_attention(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, int64_t head_num, c10::string_view input_layout, const ::std::optional<at::Tensor> & pse={}, const ::std::optional<at::Tensor> & padding_mask={}, const ::std::optional<at::Tensor> & atten_mask={}, double scale=1., double keep_prob=1., int64_t pre_tockens=2147483647, int64_t next_tockens=2147483647, int64_t inner_precise=0, at::OptionalIntArrayRef prefix=::std::nullopt, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_seq_kvlen=::std::nullopt, int64_t sparse_mode=0, bool gen_mask_parallel=true, bool sync=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_fusion_attention_grad(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & dy, int64_t head_num, c10::string_view input_layout, const ::std::optional<at::Tensor> & pse={}, const ::std::optional<at::Tensor> & padding_mask={}, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & softmax_max={}, const ::std::optional<at::Tensor> & softmax_sum={}, const ::std::optional<at::Tensor> & softmax_in={}, const ::std::optional<at::Tensor> & attention_in={}, double scale_value=1., double keep_prob=1., int64_t pre_tockens=2147483647, int64_t next_tockens=2147483647, int64_t inner_precise=0, int64_t seed=0, int64_t offset=0, int64_t numels=0, at::OptionalIntArrayRef prefix=::std::nullopt, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_seq_kvlen=::std::nullopt, int64_t sparse_mode=0, bool gen_mask_parallel=true, bool sync=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,int64_t,int64_t,int64_t> npu_fusion_attention_v2(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, int64_t head_num, c10::string_view input_layout, const ::std::optional<at::Tensor> & pse={}, const ::std::optional<at::Tensor> & padding_mask={}, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & query_rope={}, const ::std::optional<at::Tensor> & key_rope={}, double scale=1., double keep_prob=1., int64_t pre_tokens=2147483647, int64_t next_tokens=2147483647, int64_t inner_precise=0, at::OptionalIntArrayRef prefix=::std::nullopt, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_seq_kvlen=::std::nullopt, int64_t sparse_mode=0, bool gen_mask_parallel=true, bool sync=false, int64_t pse_type=1, at::OptionalIntArrayRef q_start_idx=::std::nullopt, at::OptionalIntArrayRef kv_start_idx=::std::nullopt);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_fusion_attention_grad_v2(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & dy, int64_t head_num, c10::string_view input_layout, const ::std::optional<at::Tensor> & pse={}, const ::std::optional<at::Tensor> & padding_mask={}, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & softmax_max={}, const ::std::optional<at::Tensor> & softmax_sum={}, const ::std::optional<at::Tensor> & softmax_in={}, const ::std::optional<at::Tensor> & attention_in={}, const ::std::optional<at::Tensor> & query_rope={}, const ::std::optional<at::Tensor> & key_rope={}, double scale_value=1., double keep_prob=1., int64_t pre_tokens=2147483647, int64_t next_tokens=2147483647, int64_t inner_precise=0, int64_t seed=0, int64_t offset=0, int64_t numels=0, at::OptionalIntArrayRef prefix=::std::nullopt, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_seq_kvlen=::std::nullopt, int64_t sparse_mode=0, bool gen_mask_parallel=true, bool sync=false, int64_t pse_type=1, at::OptionalIntArrayRef q_start_idx=::std::nullopt, at::OptionalIntArrayRef kv_start_idx=::std::nullopt);
::std::vector<at::Tensor> npu_fused_attention_layernorm_qkv_fwd(const at::Tensor & x, const at::Tensor & kernel_query, const at::Tensor & kernel_key, const at::Tensor & kernel_value, const at::Tensor & gamma, const at::Tensor & beta, const ::std::optional<at::Tensor> & bias_query={}, const ::std::optional<at::Tensor> & bias_key={}, const ::std::optional<at::Tensor> & bias_value={}, int64_t seq_len=128, int64_t num_heads=12, double eps=1e-05);
::std::vector<at::Tensor> npu_fused_attention_qkv_grad(const at::Tensor & grad_output_query, const at::Tensor & grad_output_key, const at::Tensor & grad_output_value, const at::Tensor & query_kernel, const at::Tensor & key_kernel, const at::Tensor & value_kernel, const at::Tensor & hidden_states, const at::Tensor & grad_output_ln);
::std::tuple<at::Tensor,at::Tensor> npu_geglu(const at::Tensor & self, int64_t dim=-1, int64_t approximate=1, bool activate_left=false);
at::Tensor npu_geglu_grad(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & gelu, int64_t dim=-1, int64_t approximate=1, bool activate_left=false);
at::Tensor npu_get_float_status(const at::Tensor & self, int64_t mode=0);
at::Tensor npu_giou(const at::Tensor & self, const at::Tensor & gtboxes, bool trans=false, bool is_cross=false, int64_t mode=0);
::std::tuple<at::Tensor,at::Tensor> npu_giou_backward(const at::Tensor & grad, const at::Tensor & bboxes, const at::Tensor & gtboxes, bool trans=false, bool is_cross=false, int64_t mode=0);
at::Tensor npu_grid_assign_positive(const at::Tensor & self, const at::Tensor & overlaps, const at::Tensor & box_responsible_flags, const at::Tensor & max_overlaps, const at::Tensor & argmax_overlaps, const at::Tensor & gt_max_overlaps, const at::Tensor & gt_argmax_overlaps, int64_t num_gts, double pos_iou_thr, double min_pos_iou, bool gt_max_assign_all);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_group_norm_silu(const at::Tensor & input, const ::std::optional<at::Tensor> & weight, const ::std::optional<at::Tensor> & bias, int64_t group, double eps=0.00001);
::std::vector<at::Tensor> npu_grouped_matmul(at::TensorList x, at::TensorList weight, ::std::optional<at::TensorList> bias=::std::nullopt, ::std::optional<at::TensorList> scale=::std::nullopt, ::std::optional<at::TensorList> offset=::std::nullopt, ::std::optional<at::TensorList> antiquant_scale=::std::nullopt, ::std::optional<at::TensorList> antiquant_offset=::std::nullopt, ::std::optional<at::TensorList> per_token_scale=::std::nullopt, const ::std::optional<at::Tensor> & group_list={}, ::std::optional<at::TensorList> activation_input=::std::nullopt, ::std::optional<at::TensorList> activation_quant_scale=::std::nullopt, ::std::optional<at::TensorList> activation_quant_offset=::std::nullopt, ::std::optional<int64_t> split_item=0, ::std::optional<int64_t> group_type=::std::nullopt, ::std::optional<int64_t> group_list_type=0, ::std::optional<int64_t> act_type=0, at::OptionalIntArrayRef tuning_config=::std::nullopt, ::std::optional<at::ScalarType> output_dtype=::std::nullopt);
::std::vector<at::Tensor> npu_grouped_matmul(at::TensorList x, at::TensorList weight, ::std::optional<at::TensorList> bias=::std::nullopt, ::std::optional<at::TensorList> scale=::std::nullopt, ::std::optional<at::TensorList> offset=::std::nullopt, ::std::optional<at::TensorList> antiquant_scale=::std::nullopt, ::std::optional<at::TensorList> antiquant_offset=::std::nullopt, ::std::optional<at::TensorList> per_token_scale=::std::nullopt, at::OptionalIntArrayRef group_list=::std::nullopt, ::std::optional<at::TensorList> activation_input=::std::nullopt, ::std::optional<at::TensorList> activation_quant_scale=::std::nullopt, ::std::optional<at::TensorList> activation_quant_offset=::std::nullopt, ::std::optional<int64_t> split_item=0, ::std::optional<int64_t> group_type=::std::nullopt, ::std::optional<int64_t> group_list_type=0, ::std::optional<int64_t> act_type=0, ::std::optional<at::ScalarType> output_dtype=::std::nullopt);
at::Tensor npu_grouped_matmul_finalize_routing(const at::Tensor & x, const at::Tensor & w, const at::Tensor & group_list, const ::std::optional<at::Tensor> & scale={}, const ::std::optional<at::Tensor> & bias={}, const ::std::optional<at::Tensor> & offset={}, const ::std::optional<at::Tensor> & pertoken_scale={}, const ::std::optional<at::Tensor> & shared_input={}, const ::std::optional<at::Tensor> & logit={}, const ::std::optional<at::Tensor> & row_index={}, ::std::optional<at::ScalarType> dtype=::std::nullopt, ::std::optional<double> shared_input_weight=1.0, ::std::optional<int64_t> shared_input_offset=0, ::std::optional<int64_t> output_bs=0, ::std::optional<int64_t> group_list_type=1);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_gru(const at::Tensor & input, const at::Tensor & hx, const at::Tensor & weight_input, const at::Tensor & weight_hidden, const at::Tensor & bias_input, const at::Tensor & bias_hidden, const at::Tensor & seq_length, bool has_biases, int64_t num_layers, double dropout, bool train, bool bidirectional, bool batch_first);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_gru_backward(const ::std::optional<at::Tensor> & grady, const ::std::optional<at::Tensor> & gradh, const at::Tensor & input, const at::Tensor & weight_input, const at::Tensor & weight_hidden, const at::Tensor & bias_input, const at::Tensor & bias_hidden, const at::Tensor & seq_length, const at::Tensor & hx, const at::Tensor & y_output, const at::Tensor & h_output, const at::Tensor & output_updata, const at::Tensor & output_reset, const at::Tensor & output_new, const at::Tensor & hidden_new);
::std::tuple<at::Tensor &,at::Tensor &,at::Tensor &,at::Tensor &> npu_hans_encode_out(const at::Tensor & input, bool statistic, bool reshuff, at::Tensor & pdf, at::Tensor & mantissa, at::Tensor & fixed, at::Tensor & var);
at::Tensor & npu_hans_decode_out(const at::Tensor & mantissa, const at::Tensor & fixed, const at::Tensor & var, const at::Tensor & pdf, bool reshuff, at::Tensor & out);
::std::tuple<at::Tensor,at::Tensor> npu_ifmr(const at::Tensor & data, const at::Tensor & data_min, const at::Tensor & data_max, const at::Tensor & cumsum, double min_percentile, double max_percentile, double search_start, double search_end, double search_step, bool with_offset);
at::Tensor npu_our_incre_flash_attention(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const ::std::optional<at::Tensor> & padding_mask={}, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & pse_shift={}, at::OptionalSymIntArrayRef actual_seq_lengths=::std::nullopt, const ::std::optional<at::Tensor> & antiquant_scale={}, const ::std::optional<at::Tensor> & antiquant_offset={}, const ::std::optional<at::Tensor> & block_table={}, const ::std::optional<at::Tensor> & dequant_scale1={}, const ::std::optional<at::Tensor> & quant_scale1={}, const ::std::optional<at::Tensor> & dequant_scale2={}, const ::std::optional<at::Tensor> & quant_scale2={}, const ::std::optional<at::Tensor> & quant_offset2={}, const ::std::optional<at::Tensor> & kv_padding_size={}, int64_t num_heads=1, double scale_value=1.0, c10::string_view input_layout="BSH", int64_t num_key_value_heads=0, int64_t block_size=0, int64_t inner_precise=1);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_sparse_paged_fusion_attention(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & blocktable, const at::Tensor & l1_cent, const at::Tensor & block_ids, const at::Tensor & total_seq_len, const at::Tensor & block_position, const at::Tensor & page_position_length, const at::Tensor & max_page_position_length, const ::std::optional<at::Tensor> & pse_shift={}, const ::std::optional<at::Tensor> & attention_mask={}, at::OptionalSymIntArrayRef actual_seq_lengths=::std::nullopt, const ::std::optional<at::Tensor> & dequant_scale1={}, const ::std::optional<at::Tensor> & quant_scale1={}, const ::std::optional<at::Tensor> & dequant_scale2={}, const ::std::optional<at::Tensor> & quant_scale2={}, const ::std::optional<at::Tensor> & quant_offset2={}, const ::std::optional<at::Tensor> & antiquant_scale={}, const ::std::optional<at::Tensor> & antiquant_offset={}, const ::std::optional<at::Tensor> & kv_padding_size={}, int64_t num_heads=1, double scale_value=1.0, c10::string_view input_layout="BSH", int64_t num_key_value_heads=0, int64_t block_size=0, int64_t inner_precise=1);
at::Tensor npu_sparse_paged_attention(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const ::std::optional<at::Tensor> & padding_mask={}, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & pse_shift={}, at::OptionalSymIntArrayRef actual_seq_lengths=::std::nullopt, const ::std::optional<at::Tensor> & antiquant_scale={}, const ::std::optional<at::Tensor> & antiquant_offset={}, const ::std::optional<at::Tensor> & block_table={}, const ::std::optional<at::Tensor> & block_position={}, const ::std::optional<at::Tensor> & dequant_scale1={}, const ::std::optional<at::Tensor> & quant_scale1={}, const ::std::optional<at::Tensor> & dequant_scale2={}, const ::std::optional<at::Tensor> & quant_scale2={}, const ::std::optional<at::Tensor> & quant_offset2={}, const ::std::optional<at::Tensor> & kv_padding_size={}, int64_t num_heads=1, double scale_value=1.0, c10::string_view input_layout="BSH", int64_t num_key_value_heads=0, int64_t block_size=0, int64_t inner_precise=1);
::std::tuple<at::Tensor,at::Tensor> npu_cent_select(const at::Tensor & query, const at::Tensor & l1_cent, const at::Tensor & block_ids, const at::Tensor & block_table, const at::Tensor & seq_len);
at::Tensor npu_interleave_rope(const at::Tensor & x, const at::Tensor & cos, const at::Tensor & sin);
at::Tensor npu_indexing(const at::Tensor & self, at::IntArrayRef begin, at::IntArrayRef end, at::IntArrayRef strides, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0);
at::Tensor & npu_indexing_out(const at::Tensor & self, at::IntArrayRef begin, at::IntArrayRef end, at::IntArrayRef strides, int64_t begin_mask, int64_t end_mask, int64_t ellipsis_mask, int64_t new_axis_mask, int64_t shrink_axis_mask, at::Tensor & out);
at::Tensor npu_iou(const at::Tensor & bboxes, const at::Tensor & gtboxes, int64_t mode=0);
at::Tensor npu_layer_norm_eval(const at::Tensor & input, at::IntArrayRef normalized_shape, const ::std::optional<at::Tensor> & weight={}, const ::std::optional<at::Tensor> & bias={}, double eps=1e-05);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_layernorm_grad(const at::Tensor & grad_out, const at::Tensor & input, at::IntArrayRef normalized_shape, const at::Tensor & mean, const at::Tensor & rstd, const ::std::optional<at::Tensor> & weight, const ::std::optional<at::Tensor> & bias);
at::Tensor npu_linear(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias={});
::std::tuple<at::Tensor,at::Tensor> npu_linear_backward(const at::Tensor & grad, const at::Tensor & input, const at::Tensor & weight);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_lstm(const at::Tensor & input, const at::Tensor & weight, const at::Tensor & bias, const at::Tensor & seq_mask, const at::Tensor & h, const at::Tensor & c, bool has_biases, int64_t num_layers, double dropout, bool train, bool bidirectional, bool batch_first, bool flag_seq, bool direction);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_lstm_backward(const ::std::optional<at::Tensor> & grady, const ::std::optional<at::Tensor> & gradh, const ::std::optional<at::Tensor> & gradc, const at::Tensor & input, const at::Tensor & weight, const at::Tensor & bias, const at::Tensor & hx, const at::Tensor & cx, const at::Tensor & y_output, const at::Tensor & h_output, const at::Tensor & c_output, const at::Tensor & i, const at::Tensor & j, const at::Tensor & f, const at::Tensor & o, const at::Tensor & tanhc);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_lstm_cell(const at::Tensor & input, const at::Tensor & w_ih, const at::Tensor & w_hh, const at::Tensor & h, const at::Tensor & c, const ::std::optional<at::Tensor> & b_ih={}, const ::std::optional<at::Tensor> & b_hh={});
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_lstm_cell_backward(const ::std::optional<at::Tensor> & grady, const ::std::optional<at::Tensor> & gradh, const ::std::optional<at::Tensor> & gradc, const at::Tensor & input, const at::Tensor & w_ih, const at::Tensor & w_hh, const at::Tensor & h, const at::Tensor & c, const at::Tensor & y_output, const at::Tensor & h_output, const at::Tensor & c_output, const at::Tensor & i, const at::Tensor & j, const at::Tensor & f, const at::Tensor & o, const at::Tensor & tanhc);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_lstm_data(const at::Tensor & input, const at::Tensor & batch_sizes, const at::Tensor & weight, const at::Tensor & bias, const at::Tensor & seq_mask, const at::Tensor & h, const at::Tensor & c, bool has_biases, int64_t num_layers, double dropout, bool train, bool bidirectional, bool batch_first, bool flag_seq, bool direction);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_lstm_data_backward(const ::std::optional<at::Tensor> & grady_opt, const ::std::optional<at::Tensor> & gradh_opt, const ::std::optional<at::Tensor> & gradc_opt, const at::Tensor & input, const at::Tensor & batch_sizes, const at::Tensor & weight, const at::Tensor & bias, const at::Tensor & init_h, const at::Tensor & init_c, const at::Tensor & y, const at::Tensor & h, const at::Tensor & c, const at::Tensor & i, const at::Tensor & j, const at::Tensor & f, const at::Tensor & o, const at::Tensor & tanhc, bool flag_direction);
at::Tensor npu_masked_fill_range(const at::Tensor & self, const at::Tensor & start, const at::Tensor & end, const at::Tensor & value, int64_t axis=-1);
at::Tensor npu_masked_softmax_with_rel_pos_bias(const at::Tensor & x, const ::std::optional<at::Tensor> & atten_mask, const at::Tensor & relative_pos_bias, double scale_value=1.0, int64_t inner_precision_mode=0);
::std::tuple<at::Tensor,at::Tensor> npu_max(const at::Tensor & self, int64_t dim, bool keepdim=false);
::std::tuple<at::Tensor,at::Tensor> npu_max(const at::Tensor & self, at::Dimname dim, bool keepdim=false);
at::Tensor npu_max_backward(const at::Tensor & grad, int64_t dim, const at::Tensor & indices, c10::SymIntArrayRef sizes, bool keepdim);
::std::tuple<at::Tensor,at::Tensor> npu_min(const at::Tensor & self, int64_t dim, bool keepdim=false);
::std::tuple<at::Tensor,at::Tensor> npu_min(const at::Tensor & self, at::Dimname dim, bool keepdim=false);
at::Tensor npu_min_backward(const at::Tensor & grad, int64_t dim, const at::Tensor & indices, c10::SymIntArrayRef sizes, bool keepdim);
at::Tensor npu_mish(const at::Tensor & self);
at::Tensor npu_mish_backward(const at::Tensor & grad, const at::Tensor & input);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_mla_prolog(const at::Tensor & token_x, const at::Tensor & weight_dq, const at::Tensor & weight_uq_qr, const at::Tensor & weight_uk, const at::Tensor & weight_dkv_kr, const at::Tensor & rmsnorm_gamma_cq, const at::Tensor & rmsnorm_gamma_ckv, const at::Tensor & rope_sin, const at::Tensor & rope_cos, const at::Tensor & cache_index, const at::Tensor & kv_cache, const at::Tensor & kr_cache, const ::std::optional<at::Tensor> & dequant_scale_x={}, const ::std::optional<at::Tensor> & dequant_scale_w_dq={}, const ::std::optional<at::Tensor> & dequant_scale_w_uq_qr={}, const ::std::optional<at::Tensor> & dequant_scale_w_dkv_kr={}, const ::std::optional<at::Tensor> & quant_scale_ckv={}, const ::std::optional<at::Tensor> & quant_scale_ckr={}, const ::std::optional<at::Tensor> & smooth_scales_cq={}, double rmsnorm_epsilon_cq=1e-05, double rmsnorm_epsilon_ckv=1e-05, c10::string_view cache_mode="PA_BSND");
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_mla_prolog_v2(const at::Tensor & token_x, const at::Tensor & weight_dq, const at::Tensor & weight_uq_qr, const at::Tensor & weight_uk, const at::Tensor & weight_dkv_kr, const at::Tensor & rmsnorm_gamma_cq, const at::Tensor & rmsnorm_gamma_ckv, const at::Tensor & rope_sin, const at::Tensor & rope_cos, const at::Tensor & cache_index, const at::Tensor & kv_cache, const at::Tensor & kr_cache, const ::std::optional<at::Tensor> & dequant_scale_x={}, const ::std::optional<at::Tensor> & dequant_scale_w_dq={}, const ::std::optional<at::Tensor> & dequant_scale_w_uq_qr={}, const ::std::optional<at::Tensor> & dequant_scale_w_dkv_kr={}, const ::std::optional<at::Tensor> & quant_scale_ckv={}, const ::std::optional<at::Tensor> & quant_scale_ckr={}, const ::std::optional<at::Tensor> & smooth_scales_cq={}, double rmsnorm_epsilon_cq=1e-05, double rmsnorm_epsilon_ckv=1e-05, c10::string_view cache_mode="PA_BSND");
at::Tensor npu_mm_all_reduce_base(const at::Tensor & x1, const at::Tensor & x2, c10::string_view hcom, c10::string_view reduce_op="sum", const ::std::optional<at::Tensor> & bias={}, const ::std::optional<at::Tensor> & antiquant_scale={}, const ::std::optional<at::Tensor> & antiquant_offset={}, const ::std::optional<at::Tensor> & x3={}, const ::std::optional<at::Tensor> & dequant_scale={}, const ::std::optional<at::Tensor> & pertoken_scale={}, const ::std::optional<at::Tensor> & comm_quant_scale_1={}, const ::std::optional<at::Tensor> & comm_quant_scale_2={}, int64_t antiquant_group_size=0, int64_t comm_turn=0);
at::Tensor npu_mm_reduce_scatter_base(const at::Tensor & self, const at::Tensor & x2, c10::string_view hcom, int64_t world_size, c10::string_view reduce_op="sum", const ::std::optional<at::Tensor> & bias={}, int64_t comm_turn=0);
at::Tensor npu_moe_compute_expert_tokens(const at::Tensor & sorted_expert_for_source_row, int64_t num_expert);
at::Tensor npu_moe_finalize_routing(const at::Tensor & expanded_permuted_rows, const ::std::optional<at::Tensor> & skip1, const ::std::optional<at::Tensor> & skip2, const ::std::optional<at::Tensor> & bias, const ::std::optional<at::Tensor> & scales, const at::Tensor & expanded_src_to_dst_row, const ::std::optional<at::Tensor> & export_for_source_row, ::std::optional<int64_t> drop_pad_mode=0);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_moe_gating_top_k_softmax(const at::Tensor & x, const ::std::optional<at::Tensor> & finished={}, int64_t k=1);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_moe_gating_top_k(const at::Tensor & x, int64_t k, const ::std::optional<at::Tensor> & bias={}, int64_t k_group=1, int64_t group_count=1, int64_t group_select_mode=0, int64_t renorm=0, int64_t norm_type=0, bool out_flag=false, double routed_scaling_factor=1.0, double eps=1e-20);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_moe_init_routing(const at::Tensor & x, const at::Tensor & row_idx, const at::Tensor & expert_idx, int64_t active_num);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_moe_init_routing_v2(const at::Tensor & x, const at::Tensor & expert_idx, const ::std::optional<at::Tensor> & scale={}, const ::std::optional<at::Tensor> & offset={}, int64_t active_num=-1, int64_t expert_capacity=-1, int64_t expert_num=-1, int64_t drop_pad_mode=0, int64_t expert_tokens_num_type=0, bool expert_tokens_num_flag=false, int64_t quant_mode=0, at::IntArrayRef active_expert_range={}, int64_t row_idx_type=0);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_grouped_matmul_swiglu_quant(const at::Tensor & x, const at::Tensor & weight, const at::Tensor & group_list, const at::Tensor & weight_scale, const at::Tensor & x_scale, const ::std::optional<at::Tensor> & bias={}, const ::std::optional<at::Tensor> & offset={});
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_moe_distribute_dispatch(const at::Tensor & x, const at::Tensor & expert_ids, c10::string_view group_ep, int64_t ep_world_size, int64_t ep_rank_id, int64_t moe_expert_num, const ::std::optional<at::Tensor> & scales={}, const ::std::optional<at::Tensor> & x_active_mask={}, const ::std::optional<at::Tensor> & expert_scales={}, c10::string_view group_tp="", int64_t tp_world_size=0, int64_t tp_rank_id=0, int64_t expert_shard_type=0, int64_t shared_expert_num=1, int64_t shared_expert_rank_num=0, int64_t quant_mode=0, int64_t global_bs=0, int64_t expert_token_nums_type=1);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_moe_distribute_dispatch_v2(const at::Tensor & x, const at::Tensor & expert_ids, c10::string_view group_ep, int64_t ep_world_size, int64_t ep_rank_id, int64_t moe_expert_num, const ::std::optional<at::Tensor> & scales={}, const ::std::optional<at::Tensor> & x_active_mask={}, const ::std::optional<at::Tensor> & expert_scales={}, c10::string_view group_tp="", int64_t tp_world_size=0, int64_t tp_rank_id=0, int64_t expert_shard_type=0, int64_t shared_expert_num=1, int64_t shared_expert_rank_num=0, int64_t quant_mode=0, int64_t global_bs=0, int64_t expert_token_nums_type=1);
at::Tensor npu_moe_distribute_combine(const at::Tensor & expand_x, const at::Tensor & expert_ids, const at::Tensor & expand_idx, const at::Tensor & ep_send_counts, const at::Tensor & expert_scales, c10::string_view group_ep, int64_t ep_world_size, int64_t ep_rank_id, int64_t moe_expert_num, const ::std::optional<at::Tensor> & tp_send_counts={}, const ::std::optional<at::Tensor> & x_active_mask={}, const ::std::optional<at::Tensor> & activation_scale={}, const ::std::optional<at::Tensor> & weight_scale={}, const ::std::optional<at::Tensor> & group_list={}, const ::std::optional<at::Tensor> & expand_scales={}, const ::std::optional<at::Tensor> & shared_expert_x={}, c10::string_view group_tp="", int64_t tp_world_size=0, int64_t tp_rank_id=0, int64_t expert_shard_type=0, int64_t shared_expert_num=1, int64_t shared_expert_rank_num=0, int64_t global_bs=0, int64_t out_dtype=0, int64_t comm_quant_mode=0, int64_t group_list_type=0);
at::Tensor npu_moe_distribute_combine_v2(const at::Tensor & expand_x, const at::Tensor & expert_ids, const at::Tensor & assist_info_for_combine, const at::Tensor & ep_send_counts, const at::Tensor & expert_scales, c10::string_view group_ep, int64_t ep_world_size, int64_t ep_rank_id, int64_t moe_expert_num, const ::std::optional<at::Tensor> & tp_send_counts={}, const ::std::optional<at::Tensor> & x_active_mask={}, const ::std::optional<at::Tensor> & expand_scales={}, const ::std::optional<at::Tensor> & shared_expert_x={}, c10::string_view group_tp="", int64_t tp_world_size=0, int64_t tp_rank_id=0, int64_t expert_shard_type=0, int64_t shared_expert_num=1, int64_t shared_expert_rank_num=0, int64_t global_bs=0, int64_t comm_quant_mode=0);
at::Tensor _npu_distribute_barrier(const at::Tensor & x_ref, c10::string_view group, int64_t world_size);
at::Tensor npu_moe_eplb_update_expert(const at::Tensor & expert_ids, const at::Tensor & eplb_table, int64_t local_rank_id, int64_t world_size, int64_t balance_mode=0);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_moe_re_routing(const at::Tensor & tokens, const at::Tensor & expert_token_num_per_rank, const ::std::optional<at::Tensor> & per_token_scales={}, int64_t expert_token_num_type=1, int64_t idx_type=0);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_moe_distribute_combine_add_rms_norm(const at::Tensor & expand_x, const at::Tensor & expert_ids, const at::Tensor & expand_idx, const at::Tensor & ep_send_counts, const at::Tensor & expert_scales, const at::Tensor & residual_x, const at::Tensor & gamma, c10::string_view group_ep, int64_t ep_world_size, int64_t ep_rank_id, int64_t moe_expert_num, const ::std::optional<at::Tensor> & tp_send_counts={}, const ::std::optional<at::Tensor> & x_active_mask={}, const ::std::optional<at::Tensor> & activation_scale={}, const ::std::optional<at::Tensor> & weight_scale={}, const ::std::optional<at::Tensor> & group_list={}, const ::std::optional<at::Tensor> & expand_scales={}, const ::std::optional<at::Tensor> & shared_expert_x={}, c10::string_view group_tp="", int64_t tp_world_size=0, int64_t tp_rank_id=0, int64_t expert_shard_type=0, int64_t shared_expert_num=1, int64_t shared_expert_rank_num=0, int64_t global_bs=0, int64_t out_dtype=0, int64_t comm_quant_mode=0, int64_t group_list_type=0, c10::string_view comm_alg="", double norm_eps=1e-06);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_multi_head_attention(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & query_weight, const at::Tensor & key_weight, const at::Tensor & value_weight, const at::Tensor & attn_mask, const at::Tensor & out_proj_weight, const ::std::optional<at::Tensor> & query_bias, const ::std::optional<at::Tensor> & key_bias, const ::std::optional<at::Tensor> & value_bias, const ::std::optional<at::Tensor> & out_proj_bias, const ::std::optional<at::Tensor> & dropout_mask, int64_t attn_head_num, int64_t attn_dim_per_head, int64_t src_len, int64_t tgt_len, double dropout_prob, bool softmax_use_float);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_multi_head_attention_backward(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & query_weight, const at::Tensor & key_weight, const at::Tensor & value_weight, const at::Tensor & out_proj_weight, const ::std::optional<at::Tensor> & query_bias, const ::std::optional<at::Tensor> & key_bias, const ::std::optional<at::Tensor> & value_bias, const ::std::optional<at::Tensor> & out_proj_bias, const at::Tensor & query_res, const at::Tensor & key_res, const at::Tensor & value_res, const at::Tensor & attn_scores, const at::Tensor & attn_res, const at::Tensor & context, const at::Tensor & y_grad, const at::Tensor & dropout_mask, int64_t attn_head_num, int64_t attn_dim_per_head, int64_t src_len, int64_t tgt_len, double dropout_prob, bool softmax_use_float);
::std::tuple<at::Tensor,at::Tensor,int64_t,int64_t,int64_t> npu_multi_head_attention_v2(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & alibi_mask={}, double scale=1.0, int64_t head_num=1, c10::string_view input_layout="BNSD", double keep_prob=1., int64_t pre_tokens=2147483647, int64_t next_tokens=1, bool gen_mask_parallel=true, bool sync=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_multi_head_attention_v2_grad(const at::Tensor & attention_score_grad, const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & softmax_log_max_sum, const at::Tensor & attention_score, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & alibi_mask={}, double scale=1.0, int64_t head_num=1, c10::string_view input_layout="BNSD", double keep_prob=1., int64_t pre_tokens=2147483647, int64_t next_tokens=1, int64_t seed=0, int64_t offset=0, int64_t numels=0, bool gen_mask_parallel=true, bool sync=false);
::std::tuple<at::Tensor,at::Tensor> npu_nms_rotated(const at::Tensor & self, const at::Tensor & scores, double iou_threshold, double scores_threshold=0, int64_t max_output_size=-1, int64_t mode=0);
::std::tuple<at::Tensor,at::Tensor> npu_nms_v4(const at::Tensor & self, const at::Tensor & scores, const at::Scalar & max_output_size, const at::Tensor & iou_threshold, const at::Tensor & scores_threshold, bool pad_to_max_output_size=false);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_nms_with_mask(const at::Tensor & input, const at::Scalar & iou_threshold);
at::Tensor npu_normalize_batch(const at::Tensor & self, const at::Tensor & seq_len, int64_t normalize_type=0);
at::Tensor npu_one_hot(const at::Tensor & self, int64_t num_classes=-1, int64_t depth=1, const at::Scalar & on_value=1, const at::Scalar & off_value=0);
at::Tensor npu_pad(const at::Tensor & input, at::IntArrayRef paddings);
at::Tensor npu_prompt_flash_attention(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const ::std::optional<at::Tensor> & padding_mask={}, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & pse_shift={}, at::OptionalIntArrayRef actual_seq_lengths=::std::nullopt, const ::std::optional<at::Tensor> & deq_scale1={}, const ::std::optional<at::Tensor> & quant_scale1={}, const ::std::optional<at::Tensor> & deq_scale2={}, const ::std::optional<at::Tensor> & quant_scale2={}, const ::std::optional<at::Tensor> & quant_offset2={}, int64_t num_heads=1, double scale_value=1.0, int64_t pre_tokens=2147473647, int64_t next_tokens=0, c10::string_view input_layout="BSH", int64_t num_key_value_heads=0, at::OptionalIntArrayRef actual_seq_lengths_kv=::std::nullopt, int64_t sparse_mode=0);
at::Tensor npu_ps_roi_pooling(const at::Tensor & self, const at::Tensor & rois, double spatial_scale, int64_t group_size, int64_t output_dim);
at::Tensor npu_ps_roi_pooling_backward(const at::Tensor & output_grad, const at::Tensor & rois, double spatial_scale, int64_t group_size, int64_t output_dim, c10::SymIntArrayRef input_size);
at::Tensor npu_ptiou(const at::Tensor & bboxes, const at::Tensor & gtboxes, int64_t mode=0);
void npu_prefetch(const at::Tensor & self, const ::std::optional<at::Tensor> & dependency, int64_t max_size, int64_t offset=0);
at::Tensor npu_quant_conv2d(const at::Tensor & input, const at::Tensor & weight, const at::Tensor & scale, at::IntArrayRef strides=1, at::IntArrayRef pads=0, at::IntArrayRef dilations=1, int64_t groups=1, int64_t offset_x=0, c10::string_view round_mode="rint", ::std::optional<at::ScalarType> output_dtype=::std::nullopt, const ::std::optional<at::Tensor> & bias={}, const ::std::optional<at::Tensor> & offset={});
at::Tensor npu_quant_matmul(const at::Tensor & x1, const at::Tensor & x2, const at::Tensor & scale, const ::std::optional<at::Tensor> & offset={}, const ::std::optional<at::Tensor> & pertoken_scale={}, const ::std::optional<at::Tensor> & bias={}, ::std::optional<at::ScalarType> output_dtype=::std::nullopt, at::OptionalSymIntArrayRef group_sizes=::std::nullopt);
at::Tensor npu_quant_matmul_dequant(const at::Tensor & x, const at::Tensor & quantized_weight, const at::Tensor & weight_scale, const ::std::optional<at::Tensor> & bias={}, const ::std::optional<at::Tensor> & x_scale={}, const ::std::optional<at::Tensor> & x_offset={}, const ::std::optional<at::Tensor> & smooth_scale={}, ::std::optional<c10::string_view> quant_mode="pertoken");
at::Tensor npu_quant_grouped_matmul_dequant(const at::Tensor & x, const at::Tensor & quantized_weight, const at::Tensor & weight_scale, const at::Tensor & group_list, const ::std::optional<at::Tensor> & bias={}, const ::std::optional<at::Tensor> & x_scale={}, const ::std::optional<at::Tensor> & x_offset={}, const ::std::optional<at::Tensor> & smooth_scale={}, ::std::optional<c10::string_view> quant_mode="pertoken");
at::Tensor npu_quant_scatter(const at::Tensor & self, const at::Tensor & indices, const at::Tensor & updates, const at::Tensor & quant_scales, const ::std::optional<at::Tensor> & quant_zero_points={}, int64_t axis=0, int64_t quant_axis=1, c10::string_view reduce="update");
at::Tensor & npu_quant_scatter_(at::Tensor & self, const at::Tensor & indices, const at::Tensor & updates, const at::Tensor & quant_scales, const ::std::optional<at::Tensor> & quant_zero_points={}, int64_t axis=0, int64_t quant_axis=1, c10::string_view reduce="update");
at::Tensor npu_quantize(const at::Tensor & self, const at::Tensor & scales, const ::std::optional<at::Tensor> & zero_points, at::ScalarType dtype, int64_t axis=1, bool div_mode=true);
::std::tuple<at::Tensor,at::Tensor> npu_kronecker_quant(const at::Tensor & x, const at::Tensor & kronecker_p1, const at::Tensor & kronecker_p2, ::std::optional<double> clip_ratio=::std::nullopt, ::std::optional<at::ScalarType> dst_dtype=::std::nullopt);
at::Tensor npu_group_quant(const at::Tensor & x, const at::Tensor & scale, const at::Tensor & group_index, const ::std::optional<at::Tensor> & offset={}, ::std::optional<at::ScalarType> dst_dtype=::std::nullopt);
::std::tuple<at::Tensor,at::Tensor> npu_random_choice_with_mask(const at::Tensor & x, int64_t count=256, int64_t seed=0, int64_t seed2=0);
at::Tensor npu_reshape(const at::Tensor & self, at::IntArrayRef shape, bool can_refresh=false);
at::Tensor & npu_reshape_out(const at::Tensor & self, at::IntArrayRef shape, bool can_refresh, at::Tensor & out);
::std::tuple<at::Tensor,at::Tensor> npu_rms_norm(const at::Tensor & self, const at::Tensor & gamma, double epsilon=1e-06);
::std::tuple<at::Tensor,at::Tensor> npu_gemma_rms_norm(const at::Tensor & self, const at::Tensor & gamma, double epsilon=1e-06);
::std::tuple<at::Tensor,at::Tensor> npu_rms_norm_backward(const at::Tensor & dy, const at::Tensor & self, const at::Tensor & gamma, const at::Tensor & rstd);
at::Tensor npu_roi_align(const at::Tensor & self, const at::Tensor & rois, double spatial_scale, int64_t pooled_height, int64_t pooled_width, int64_t sample_num, int64_t roi_end_mode);
at::Tensor npu_roi_alignbk(const at::Tensor & self, const at::Tensor & rois, at::IntArrayRef xdiff_shape, int64_t pooled_width, int64_t pooled_height, double spatial_scale, int64_t sample_num, ::std::optional<int64_t> roi_end_mode=::std::nullopt);
at::Tensor npu_rotary_mul(const at::Tensor & self, const at::Tensor & r1, const at::Tensor & r2, c10::string_view rotary_mode="half");
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_rotary_mul_backward(const at::Tensor & grad, const at::Tensor & self, const at::Tensor & r1, const at::Tensor & r2, c10::string_view rotary_mode="half");
::std::tuple<at::Tensor,at::Tensor> npu_mrope(const at::Tensor & positions, const at::Tensor & query, const at::Tensor & key, const at::Tensor & cos_sin_cache, int64_t head_size, at::OptionalIntArrayRef mrope_section=::std::nullopt, ::std::optional<c10::string_view> rotary_mode="half");
at::Tensor npu_rotated_box_decode(const at::Tensor & self, const at::Tensor & deltas, const at::Tensor & weight);
at::Tensor npu_rotated_box_encode(const at::Tensor & self, const at::Tensor & gt_bboxes, const at::Tensor & weight);
at::Tensor npu_rotated_iou(const at::Tensor & self, const at::Tensor & query_boxes, bool trans=false, int64_t mode=0, bool is_cross=true, double v_threshold=0.0, double e_threshold=0.0);
at::Tensor npu_rotated_overlaps(const at::Tensor & self, const at::Tensor & query_boxes, bool trans=false);
at::Tensor npu_scaled_masked_softmax(const at::Tensor & x, const at::Tensor & mask, const at::Scalar & scale=1, bool fixed_triu_mask=false);
at::Tensor npu_scaled_masked_softmax_backward(const at::Tensor & y_grad, const at::Tensor & y, const at::Tensor & mask, const at::Scalar & scale, bool fixed_triu_mask);
at::Tensor npu_scatter(const at::Tensor & self, const at::Tensor & indices, const at::Tensor & updates, int64_t dim);
::std::vector<at::Tensor> npu_scatter_list(at::TensorList self, const at::Tensor & indices, const at::Tensor & updates, const ::std::optional<at::Tensor> & mask={}, c10::string_view reduce="update", int64_t axis=-2);
void npu_scatter_list_(at::TensorList self, const at::Tensor & indices, const at::Tensor & updates, const ::std::optional<at::Tensor> & mask={}, c10::string_view reduce="update", int64_t axis=-2);
at::Tensor npu_scatter_nd_update(const at::Tensor & self, const at::Tensor & indices, const at::Tensor & updates);
at::Tensor & npu_scatter_nd_update_(at::Tensor & self, const at::Tensor & indices, const at::Tensor & updates);
at::Tensor npu_sign_bits_pack(const at::Tensor & self, int64_t size);
at::Tensor npu_sign_bits_unpack(const at::Tensor & input, int64_t size, at::ScalarType dtype);
at::Tensor npu_silu(const at::Tensor & self);
at::Tensor & npu_silu_(at::Tensor & self);
at::Tensor npu_silu_backward(const at::Tensor & grad_output, const at::Tensor & x0, const at::Tensor & x1);
at::Tensor npu_slice(const at::Tensor & self, at::IntArrayRef offsets, at::IntArrayRef size);
at::Tensor & npu_slice_out(const at::Tensor & self, at::IntArrayRef offsets, at::IntArrayRef size, at::Tensor & out);
at::Tensor npu_softmax_cross_entropy_with_logits(const at::Tensor & self, const at::Tensor & labels);
at::Tensor npu_softmax_cross_entropy_with_logits_backward(const at::Tensor & grad, const at::Tensor & self, const at::Tensor & labels);
at::Tensor npu_sort_v2(const at::Tensor & self, int64_t dim=-1, bool descending=false);
at::Tensor & npu_sort_v2_out(const at::Tensor & self, int64_t dim, bool descending, at::Tensor & out);
at::Tensor npu_stride_add(const at::Tensor & self, const at::Tensor & other, const at::Scalar & offset1, const at::Scalar & offset2, const at::Scalar & c1_len);
at::Tensor npu_stride_copy(const at::Tensor & self, at::IntArrayRef shape, at::IntArrayRef stride, const at::Scalar & storage_offset);
at::Tensor & npu_stride_copy_out(const at::Tensor & self, at::IntArrayRef shape, at::IntArrayRef stride, const at::Scalar & storage_offset, at::Tensor & out);
at::Tensor npu_sub_sample(const at::Tensor & self, int64_t per_images, double positive_fraction);
at::Tensor npu_swiglu(const at::Tensor & self, int64_t dim=-1);
at::Tensor npu_swiglu_backward(const at::Tensor & grad_output, const at::Tensor & self, int64_t dim=-1);
::std::tuple<at::Tensor,at::Tensor> npu_dequant_swiglu_quant(const at::Tensor & x, const ::std::optional<at::Tensor> & weight_scale={}, const ::std::optional<at::Tensor> & activation_scale={}, const ::std::optional<at::Tensor> & bias={}, const ::std::optional<at::Tensor> & quant_scale={}, const ::std::optional<at::Tensor> & quant_offset={}, const ::std::optional<at::Tensor> & group_index={}, bool activate_left=false, int64_t quant_mode=0);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_dequant_rope_quant_kvcache(const at::Tensor & x, const at::Tensor & cos, const at::Tensor & sin, const at::Tensor & k_cache, const at::Tensor & v_cache, const at::Tensor & indices, const at::Tensor & scale_k, const at::Tensor & scale_v, at::IntArrayRef size_splits, const ::std::optional<at::Tensor> & offset_k={}, const ::std::optional<at::Tensor> & offset_v={}, const ::std::optional<at::Tensor> & weight_scale={}, const ::std::optional<at::Tensor> & activation_scale={}, const ::std::optional<at::Tensor> & bias={}, int64_t quant_mode=0, c10::string_view input_layout="BSND", bool kv_output=false, c10::string_view cache_mode="contiguous");
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_rope_quant_kvcache(const at::Tensor & x, const at::Tensor & cos, const at::Tensor & sin, const at::Tensor & k_cache, const at::Tensor & v_cache, const at::Tensor & indices, const at::Tensor & scale_k, const at::Tensor & scale_v, at::IntArrayRef size_splits, const ::std::optional<at::Tensor> & offset_k={}, const ::std::optional<at::Tensor> & offset_v={}, int64_t quant_mode=0, c10::string_view input_layout="BSND", bool kv_output=false, c10::string_view cache_mode="contiguous");
at::Tensor npu_dequant_bias(const at::Tensor & x, const at::Tensor & weight_scale, const ::std::optional<at::Tensor> & activation_scale, const ::std::optional<at::Tensor> & bias, ::std::optional<at::ScalarType> output_dtype=::std::nullopt);
at::Tensor npu_trans_quant_param(const at::Tensor & scale, const ::std::optional<at::Tensor> & offset={}, ::std::optional<int64_t> round_mode=0);
at::Tensor npu_transpose(const at::Tensor & self, at::IntArrayRef perm, bool require_contiguous=true);
at::Tensor & npu_transpose_out(const at::Tensor & self, at::IntArrayRef perm, bool require_contiguous, at::Tensor & out);
at::Tensor & npu_view_copy(at::Tensor & self, const at::Tensor & other, bool non_blocking);
at::Tensor npu_weight_quant_batchmatmul(const at::Tensor & x, const at::Tensor & weight, const at::Tensor & antiquant_scale, const ::std::optional<at::Tensor> & antiquant_offset={}, const ::std::optional<at::Tensor> & quant_scale={}, const ::std::optional<at::Tensor> & quant_offset={}, const ::std::optional<at::Tensor> & bias={}, int64_t antiquant_group_size=0, int64_t inner_precise=0);
at::Tensor npu_transpose_batchmatmul(const at::Tensor & input, const at::Tensor & weight, const ::std::optional<at::Tensor> & bias={}, const ::std::optional<at::Tensor> & scale={}, at::OptionalIntArrayRef perm_x1=::std::nullopt, at::OptionalIntArrayRef perm_x2=::std::nullopt, at::OptionalIntArrayRef perm_y=::std::nullopt, ::std::optional<int64_t> batch_split_factor=1);
at::Tensor npu_yolo_boxes_encode(const at::Tensor & self, const at::Tensor & gt_bboxes, const at::Tensor & stride, bool performance_mode=false);
at::Tensor & one_(at::Tensor & self);
at::Tensor repeat_interleave_backward_int(const at::Tensor & grad, const at::Tensor & self, c10::SymInt repeats, ::std::optional<int64_t> dim=::std::nullopt);
at::Tensor repeat_interleave_backward_tensor(const at::Tensor & grad, const at::Tensor & self, const at::Tensor & repeats, ::std::optional<int64_t> dim=::std::nullopt);
at::Tensor scatter_update(const at::Tensor & self, const at::Tensor & indices, const at::Tensor & updates, int64_t axis);
at::Tensor & scatter_update_(at::Tensor & self, const at::Tensor & indices, const at::Tensor & updates, int64_t axis);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> slow_conv_transpose2d_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & weight, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef output_padding, at::IntArrayRef dilation, ::std::array<bool,3> output_mask);
at::Tensor stft_backward(const at::Tensor & grad_output, const at::Tensor & self, int64_t n_fft, ::std::optional<int64_t> hop_length=::std::nullopt, ::std::optional<int64_t> win_length=::std::nullopt, const ::std::optional<at::Tensor> & window={}, bool normalized=false, ::std::optional<bool> onesided=::std::nullopt, ::std::optional<bool> return_complex=::std::nullopt);
at::Tensor fft_r2c_backward(const at::Tensor & grad, at::IntArrayRef dim, int64_t normalization, bool onesided, int64_t last_dim_size);
at::Tensor fft_c2r_backward(const at::Tensor & grad, at::IntArrayRef dim, int64_t normalization);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_cross_entropy_loss(const at::Tensor & input, const at::Tensor & target, const ::std::optional<at::Tensor> & weight={}, c10::string_view reduction="mean", int64_t ignore_index=-100, double label_smoothing=0.0, double lse_square_scale_for_zloss=0.0, bool return_zloss=false);
at::Tensor npu_cross_entropy_loss_backward(const at::Tensor & grad_loss, const at::Tensor & log_prob, const at::Tensor & target, const ::std::optional<at::Tensor> & weight={}, const ::std::optional<at::Tensor> & grad_zloss={}, const ::std::optional<at::Tensor> & lse_for_zloss={}, c10::string_view reduction="mean", int64_t ignore_index=-100, double label_smoothing=0.0, double lse_square_scale_for_zloss=0.0);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_group_norm_swish(const at::Tensor & input, int64_t num_groups, const at::Tensor & weight, const at::Tensor & bias, ::std::optional<double> eps=1e-5, ::std::optional<double> swish_scale=1.0);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_group_norm_swish_grad(const at::Tensor & grad, const at::Tensor & input, int64_t num_groups, const at::Tensor & weight, const at::Tensor & bias, const at::Tensor & mean, const at::Tensor & rstd, ::std::array<bool,3> grad_input_mask, ::std::optional<double> swish_scale=1.0);
void npu_advance_step_flashattn(at::Tensor & input_tokens, const at::Tensor & sampled_token_ids, at::Tensor & input_positions, at::Tensor & seq_lens, at::Tensor & slot_mapping, const at::Tensor & block_tables, int64_t num_seqs, int64_t num_queries, int64_t block_size);
at::Tensor & npu_grouped_matmul_add_(at::Tensor & self, const at::Tensor & x, const at::Tensor & weight, const at::Tensor & group_list, bool transpose_x=true, bool transpose_weight=false, int64_t group_type=2);
at::Tensor & npu_attn_softmax_(at::Tensor & self);
at::Tensor & npu_attn_softmax_backward_(at::Tensor & self, const at::Tensor & grad_output, const at::Tensor & values);
at::Tensor npu_gather_sparse_index(const at::Tensor & input, const at::Tensor & index);
at::Tensor npu_nsa_compress(const at::Tensor & input, const at::Tensor & weight, int64_t compress_block_size, int64_t compress_stride, at::OptionalIntArrayRef actual_seq_len=::std::nullopt);
::std::tuple<at::Tensor,at::Tensor> npu_nsa_compress_grad(const at::Tensor & grad, const at::Tensor & input, const at::Tensor & weight, int64_t compress_block_size, int64_t compress_stride, at::OptionalIntArrayRef actual_seq_len=::std::nullopt);
at::Tensor & npu_nsa_compress_infer_out(const at::Tensor & input, const at::Tensor & weight, const at::Tensor & slot_mapping, int64_t compress_block_size, int64_t compress_stride, int64_t page_block_size, const ::std::optional<at::Tensor> & block_table, at::OptionalIntArrayRef actual_seq_len, at::Tensor & cache);
::std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor> npu_nsa_compress_attention(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, double scale_value, int64_t head_num, int64_t compress_block_size, int64_t compress_stride, int64_t select_block_size, int64_t select_block_count, const ::std::optional<at::Tensor> & topk_mask={}, const ::std::optional<at::Tensor> & atten_mask={}, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_cmp_seq_kvlen=::std::nullopt, at::OptionalIntArrayRef actual_sel_seq_kvlen=::std::nullopt);
::std::tuple<at::Tensor,at::Tensor> npu_nsa_compress_attention_infer(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, double scale_value, int64_t head_num, int64_t key_value_head_num, int64_t select_block_size, int64_t select_block_count, int64_t page_block_size, int64_t compress_block_size, int64_t compress_stride, const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & block_table={}, const ::std::optional<at::Tensor> & topk_mask={}, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_cmp_seq_kvlen=::std::nullopt, at::OptionalIntArrayRef actual_sel_seq_kvlen=::std::nullopt);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_nsa_select_attention(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & topk_indices, double scale_value, int64_t head_num, int64_t select_block_size, int64_t select_block_count, const ::std::optional<at::Tensor> & atten_mask={}, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_seq_kvlen=::std::nullopt);
::std::tuple<at::Tensor,at::Tensor,at::Tensor> npu_nsa_select_attention_grad(const at::Tensor & grad, const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & attention_out, const at::Tensor & softmax_max, const at::Tensor & softmax_sum, const at::Tensor & topk_indices, double scale_value, int64_t head_num, int64_t select_block_size, int64_t select_block_count, const ::std::optional<at::Tensor> & atten_mask={}, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_seq_kvlen=::std::nullopt);
at::Tensor npu_nsa_select_attention_infer(const at::Tensor & query, const at::Tensor & key, const at::Tensor & value, const at::Tensor & topk_indices, double scale_value, int64_t head_num, int64_t key_value_head_num, int64_t select_block_size, int64_t select_block_count, int64_t page_block_size, c10::string_view layout="BSND", const ::std::optional<at::Tensor> & atten_mask={}, const ::std::optional<at::Tensor> & block_table={}, at::OptionalIntArrayRef actual_seq_qlen=::std::nullopt, at::OptionalIntArrayRef actual_seq_kvlen=::std::nullopt);
at::Tensor npu_top_k_top_p(const at::Tensor & logits, const at::Tensor & p, const at::Tensor & k);
::std::tuple<at::Tensor,at::Tensor> npu_moe_token_permute(const at::Tensor & tokens, const at::Tensor & indices, ::std::optional<int64_t> num_out_tokens=::std::nullopt, bool padded_mode=false);
at::Tensor npu_moe_token_unpermute(const at::Tensor & permuted_tokens, const at::Tensor & sorted_indices, const ::std::optional<at::Tensor> & probs={}, bool padded_mode=false, at::OptionalIntArrayRef restore_shape=::std::nullopt);

}  // namespace custom_ops
}  // namespace native
}  // namespace at_npu

#endif
